\documentclass[review]{elsarticle}

\usepackage[]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{float}
\bibliographystyle{elsarticle-harv}
\biboptions{authoryear}

\newcommand{\ra}{\rightarrow}
\newcommand{\afs}[2]{\Phi_{#1}^{(#2)}}
\newcommand{\Dfrac}[2]{%
  \ooalign{%
    $\genfrac{}{}{1.2pt}0{#1}{#2}$\cr%
    $\color{white}\genfrac{}{}{.4pt}0{\phantom{#1}}{\phantom{#2}}$}%
}
\newcommand{\cond}{\middle\vert}
\newcommand{\dslash}{/\!\!/}
\newcommand{\Coalc}[4]{\begin{bmatrix}#1\dslash #2 \\ #3\dslash #4 \end{bmatrix}}

\newcommand{\CC}{\mathcal{C}}
\newcommand{\ms}{\mathcal{S}}
\newcommand{\QQ}{\mathcal{Q}}

\newcommand{\sgcomment}[1]{{\color{red}{SG: #1}}}
\newcommand{\ikcomment}[1]{{\color{blue}{IK: #1}}}
\newcommand{\Var}{\operatorname{Var}}
\journal{Theoretical Population Biology}

\begin{document}
\begin{frontmatter}
  \title{ Taming strong selection with large sample sizes. }

  \author{Ivan Krukov}
  \author{Simon Gravel}

  \begin{abstract}
    The fate of mutations and the genetic load of populations depend on the relative importance of
    genetic drift and natural selection. In addition, the accuracy of numerical models of evolution
    depends on the strength of both selection and drift: strong selection breaks the assumptions of
    the nearly neutral model, and strong drift coupled with large sample sizes breaks
    Kingman's coalescent model.
  
    Thus, the regime with strong selection and large sample sizes, relevant 
    to the study of pathogenic variation, appears particularly daunting.
    However, we find that the competition between drift and natural selection in this regime can be
    used to define asymptotically closed recursions for the distribution of allele
    frequencies that are accurate well beyond the strong selection limit.
 
    Selection becomes more analytically tractable when the sample size $n$ is larger than twice the
    population-scaled selection coefficient: $n \ge 2Ns$ ($4Ns$ in diploids). In this regime, the
    expected number of coalescent events is larger than the number of selective events. 
    We construct the relevant transition matrices, show how they can be used to accurately compute
    distributions of allele frequencies, and discuss the boundaries of this analytically tractable
    regime. 
  \end{abstract}

\end{frontmatter}

\section{Introduction}
\label{sec_introduciton}

The allele frequency spectrum (\textit{AFS}) is an important summary of genetic diversity that is
commonly used to infer demographic history and natural selection (\textit{e.g.}
\cite{GutenkunstEtAl2009, KammEtAl2017, JouganousEtAl2017}). Given a demographic scenario of
population size histories and migrations, the diffusion approximation or coalescent simulations can
be used to obtain a predicted \textit{AFS}. By comparing predictions to the observed \textit{AFS},
one can compute likelihoods for different demographic scenarios. Unfortunately, the \textit{AFS}
calculations can be time consuming under complex demographic models, for example with multiple
populations, or with large sample sizes.

In the absence of selection, efficient computational shortcuts can be used. Coalescence models such
as \citep{fastsimcoal2, KammEtAl2017} can efficiently compute the \textit{AFS} or subsets of it. In
addition, recursion equations have been derived for moments of the neutral allele frequency
distribution \citep{KimuraCrow1964,Ewens1972,JouganousEtAl2017}. Recently, these recursions have
been useful in fitting complex demographic models to genetic data
\citep{JouganousEtAl2017,KammEtAl2017}.
 
In the presence of natural selection, coalescent models become much more complicated, and the
corresponding recursion equations do not close but
form a very large or infinite set of coupled equations \citep{DonnellyKurtz1999, JouganousEtAl2017}. Moment-based closure approximations
have been developed \citep{JouganousEtAl2017}, but these are not robust to strong selection and
their convergence properties are not well understood.

Closure of the moment equations under the neutral Wright-Fisher model occurs because the number $n_p$ of
distinct parental lineages that are sampled when drawing $n_o$ offspring lineages is at most $n_o$,
and can be less if common ancestors are found (\textit{i.e.}, if there are coalescent events): 
$n_p \le n_o$ (see Table \ref{tab_symbols} for the notation used). This does not
hold under negative selection -- selective deaths can require the drawing of $n_p>n_o$  \citep{DonnellyKurtz1999a,
  JouganousEtAl2017}. This possible increase is made explicit, for example, in the framework of the ancestral
selection graph \citep{KroneNeuhauser1997}.

The number of relevant lineages as we go back in time is a random variable that depends on the relative
importance of drift (controlled by the population size $N$) and selection (controlled by the selection coefficient $s$), but also on the sample size $n_o$. 
The number of in-sample coalescent events per generation scales as the square of the sample size $n_o$,
while the number of selective deaths is linear in $n_o$. For sufficiently large
samples, the expected number of selective deaths will be smaller than common ancestry events, which would prevent the
increase in the number of lineages. If we can show that this holds not just in expectation, but almost always,  
we can obtain recursion equations that are almost closed. 
 
Large sample sizes also bring in the complication of simultaneous coalescent events
\citep{BhaskarEtAl2014}. The additional combinatorial possibilities make the computation of
transition matrices for recursion equations more difficult.  In this article we derive these
transition matrices, and show that these are asymptotically closed even under strong selection. We
show that these transition matrices can be used to accurately model the distribution of allele
frequencies in moderate to large samples and strong selection.

In short, modeling large sample sizes makes it easier to accurately account for strong selection. 


\section{Background}
\label{sec_background}

We consider a haploid Wright-Fisher model with $N$ individuals per generation, focusing on a single
biallelic locus. For a present-day sample with $n_o$ offspring lineages at time $t$, we will be
looking for recursion equations for the allele frequency spectrum, $\afs{n_o}{t}(i_o)$, which we
define as the probability of observing $i_o$ copies of the derived allele in a sample of size $n_o$.
We will do so by considering the process of drawing parental alleles (at time $t-1$) for this finite
sample.
\begin{table}
  \centering
  \begin{tabular}{l|p{100mm}}
    Symbol & Meaning\\
    \hline
    $N$ & Population size\\
    $n_p$ & Number of sampled parental lineages (actual plus rejected samples due to selective deaths)\\
    $n_g$ & Number of gametes (intermediate)\\
    $n_o$ & Number of offspring, sample size\\
    $i_p$ & Number of derived alleles in parents\\
    $i_o$ & Number of derived alleles in offspring\\
    $t$ & Time, in generations\\
    $\Phi_{n_o}^{t}(i_o)$ & Allele frequency spectrum in $n_o$ at generation $t$\\
    $s$ & Selection advantage of the derived allele\\
    $r$ & Number of selection events (rejections) in the sample\\
    $x_p$ & Frequency of derived allele in parental generation\\
    $i_o \dslash n_o$ & A sample with $i_o$ derived alleles ``out of'' $n_o$ total lineages\\
    $\mathbf{H}\Coalc{i_p}{n_p}{i_o}{n_o}$ & Hypergeometric probability -
                                             sample $i_o \dslash n_o$ in offspring from $i_p \dslash n_p$ in parental generation\\
    $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ & Probability of transition from $i_p \dslash n_p$ in parents
                                                 to $i_o \dslash n_o$ in offspring, with $r$ selective events -
                                                 see text for a more detailed description\\
    \hline
    $(i_p, n_p)$ & Event of \textit{drawing} exactly $i_p$ derived out of $n_p$ distinct parental lineages \\
    $\mathcal{C}(i_p, n_p)$ & Event of $n_p$ parental lineages \textit{containing} $i_p$ derived alleles \\
    $\mathcal{S}(i_o, n_p)$ & Event that  $i_o$ offpring carry the derived allele and that $n_p$ distinct parental alleles were drawn \\
    $\ms_{n_o}(i_o, n_p, r)$ & Event that  $i_o$ out of $n_o$ offspring carry the derived allele, that the first $r$ draws for the 
    $n_o+1$th offspring were rejected, 
    and that $n_p$ distinct parental alleles were drawn (across all draws).
    %$\mathcal{Q}_{n_o}(i_o, r)$ & Event of $i_o$ of $n_o$ successfully drawn offspring lineages drawn with $r$ selective deaths\\
  \end{tabular}
  \caption{\label{tab_symbols} Table of symbols}
\end{table}

To model selection as part of our sampling process, we consider that a parental lineage carrying a
derived allele can be `rejected' as a result of selective death with probability $s\ge0$ (Fig.
\ref{fig_schematic}B, broken line). In such case, we keep sampling until a successful draw. This is
equivalent to the usual formulation of the Wright-Fisher model: the probability of drawing a copy of the
derived allele is $1-s$ times the probability of drawing a copy of the ancestral allele. And, because the drawing
process depends on the parental allele of both successful and rejected draws, the \textit{AFS} in the
offspring will depend on the state of the $n_p$ distinct parental lineages that were sampled. 
Because of selective rejection, $n_p$ can be larger than
$n_o$. 

To disentangle the effects of drift and selection, we may also make explicit the number of gametes
sampled in the process, $n_g$ (Fig. \ref{fig_schematic}C). The difference $n_g-n_o  \ge 0$
depends on the number of selective deaths, whereas the difference $n_p-n_g \le 0$ depends
on the number of coalescence events. This distinction will be become particularly relevant in Section
\ref{subsec_distribution}. 

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{fig/schematic.pdf}
  \caption{\label{fig_schematic} Realizations of sampling parental lineages under neutrality (A) and
    under selection (B,C). The top and bottom rows respectively represent the $n_p$ parents and
    $n_o$ offspring, with the middle row in panel (C) representing the $n_g$ gametes. Filled circles
    indicate the $i_p$, $i_g$, or $i_o$ copies of the derived allele. A line connecting two circles
    represents a successful draw, a broken line - a selective death triggering a redraw. }
\end{figure}

To express the allele-frequency spectrum $\afs{n_o}{t}(i_o)$ for $n_o$ offspring in terms of the parental
\textit{AFS} at $t-1$, we can sum over random variables $n_p$ and the number $i_p$ of distinct derived alleles
among the parents:

\begin{equation}
  \afs{n_o}{t}(i_o)=P_{n_o} (i_o) =\sum_{n_p,i_p} P_{n_o}(i_o,i_p,n_p),
\end{equation}
where the subscript $n_o$ indicates dependence on parameter $n_o$. To obtain a recursion on the
\textit{AFS}, we use an exchangeability property of the parental lineages: the order
 in which we draw previously unsampled parental lineages in the Wright-Fisher
model is random. 
In other words, we could draw a random permutation of the parental population, and select unsampled parents
in order from this permutation. We will separate properties of this permutation, which depend only
on parental \textit{AFS}, from properties of Wright-Fisher sampling, which depend on population
size and selection coefficients.  Concretely, the event $(i_o, i_p,n_p)$ that we draw $i_o$ derived offspring 
alleles from $n_p$ distinct parents of which $i_p$ are derived can be expressed as the intersection of two events,
$\mathcal{C}(i_p,n_p)$ and $\mathcal{S}_{n_o}(i_o, n_p)$. Event $\mathcal{C}(i_p,n_p)$ specifies that the
first $n_p$ parental lineages from the random permutation carry $i_p$ derived alleles. Event
$\mathcal{S}_{n_o}(i_o, n_p)$ requires that the Wright-Fisher drawing process of $n_o$ offspring drew $i_o$ derived offspring alleles 
and sampled exactly $n_p$ distinct parental lineages. Event $\mathcal{C}(i_p, n_p)$ depends on the allele
frequency distribution in the parental generation: $P(\mathcal{C}(i_p,n_p)) =\afs{n_p}{t} (i_p)$
by definition of the \textit{AFS}. Thus 

\begin{equation}
  \begin{split}
    \afs{n_o}{t}(i_o)&= \sum_{n_p,i_p} P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p), \mathcal{C}(i_p,n_p) )\\
    &=   \sum_{n_p,i_p} P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p)| \mathcal{C}(i_p,n_p) ) P(\mathcal{C}(i_p,n_p))\\
    &=   \sum_{n_p,i_p} P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p)| \mathcal{C}(i_p,n_p) )  \afs{n_p}{t-1}(i_p)%\\
%    \afs{n_o}{t} &\equiv  \sum_{n_p}  \mathbf{T}_{n_p,n_o}     \afs{n_p}{t-1}.
  \end{split}
\end{equation}
Using matrix notation to account for the sum over $i_p,$ we have 
\begin{equation}
  \afs{n_o}{t} = \sum_{n_p}  \mathbf{T}_{n_p,n_o}     \afs{n_p}{t-1}
    \label{eq_recur}
  \end{equation}
where $\mathbf{T}_{n_p,n_o}(i_o,i_p) = P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p)| \mathcal{C}(i_p,n_p) ) $ can be thought of as $(n_o+1) \times (n_p+1)$ transition
probability matrix, whose row and column indices correspond to the number of derived alleles in the
offspring and contributing parental lineages, respectively.

The AFS  $\afs{n_p}{t-1}$ for any  $n_p\leq n_o$ can be obtained by downsampling from $\afs{n_o}{t-1}$ (\textit{i.e.}, $\afs{n_p}{t-1} =
\mathbf{H}_{n_p,n_o} \afs{n_o}{t-1}$ for hypergeometric projection matrix $\mathbf{H}_{n_p,n_o}$ if
$n_p\leq n_o$). Thus, equation \eqref{eq_recur} provides a closed form recursion for $\Phi_{n_o}$ under neutrality.
This property was used in \cite{JouganousEtAl2017} to efficiently compute distributions of allele
frequencies under neutrality and in small sample sizes.

Under selection, $n_{p}$ may be larger than $n_o$, leading to a set of $N$ coupled equations that is
typically too large to solve numerically (in the diffusion limit, the number of coupled equations is
infinite). But if the number of drift events is typically larger than the number of selective
deaths, as happens in large sample sizes, the coupling is weak and we can restore approximate
closure by truncating the summation in Eq. \ref{eq_recur}:

\begin{equation}
\begin{split}
  \afs{n_o}{t}(i_o)
  &\simeq \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o}                      \afs{n_p}{t-1}\\
  &=      \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o} \afs{n_o}{t-1}\\
  &\equiv \mathbf{Q}_{n_o}                                               \afs{n_o}{t-1}\\
\end{split}
\label{eq_truncated}
\end{equation}

A jackknife approximation \citep{Gravel2016} can be used to simulate the drawing of a small number
of additional lineages and improve upon this closure approximation
($\afs{n_p}{t} \simeq J_{n_p,n_o} \afs{n_o}{t}$ with $n_p>n_o$). \cite{JouganousEtAl2017} used the
jackknife to derive approximate recursion equations under weak selection. We will show below that
closure is asymptotically maintained for large sample sizes even without requiring a jackknife
approximation.

Our first goal is to obtain an explicit recursion for the matrices in \eqref{eq_recur}. To do so, we
will need to account for multiple coalescent events, which will require some careful bookkeeping.

\section{Methods}
\label{sec_methods}

\subsection{Constructing the transition matrix}
\label{subsec_trans_mat}

Even though $\mathbf{T}_{n_p,n_o}$ in equation \ref{eq_recur} is a combinatorial probability
describing a single generation in the Wright-Fisher model, we were unable to compute an analytical
expression for it, while simultaneously allowing for multiple coalescences and multiple selective events. 
However,
we can obtain fairly simple recursions by noting that properties of a sample of size $n_o$ are
related to properties of samples of size $n_o-1.$ Similar recursions on sample size were used for
describing large sample size effects without selection in \citep{BhaskarEtAl2014}. In this section,
we provide some mathematical intuition for the recursion equation, and a more detailed derivation is provided in
Appendix \ref{subsec_apx_tpm_deriv}.

We can think of Wright-Fisher sampling as being performed one offspring at a time,
and even one draw at a time. We will define recursions by conditioning on the last draw, 
whether it is accepted or rejected. 
The recursion will be over $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o},$ defined as the probability
$P_{n_o}\left[\ms_{n_o}(i_o, n_p, r) | \mathcal{C}(i_p, n_p)\right]$ where $\ms_{n_o}(i_o, n_p, r),$ 
a generalization of  $\ms_{n_o}(i_o, n_p),$ 
is the event that $i_o$ of the first $n_o$ successfully drawn offspring are derived, 
that the following $r$ draws are rejected, and that the $n_o$ offspring and subsequent $r$ failures 
required exactly $n_p$ distinct parental draws. 
This bracket notation is convenient to keep track of
the number of relevant parental lineages (at the top) and offspring lineages (at the bottom), at the
cost of obscuring their different probabilistic role.

The last draw can be characterized by whether it was successful or rejected, whether it drew a 
derived or ancestral allele, and whether it drew a previously drawn parental lineage or not. 
The state of the sampling process prior to the last draw can be described by a number of successfully draws 
offspring $n'_o$, of which $i'_o$ are derived, a number of distinct parental lineages 
$n'_p$ of which $i'_p$ are derived, and a number of failures since last successful draw $r'$.
We show in the appendix and illustrate in Figure \ref{fig_rec_selection_dynamic_fail}  that we 
can express $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ as a sum over a small number of terms 
of the form $\mathbf{T}_{r'}\Coalc{i'_p}{n'_p}{i'_o}{n'_o}.$ If $r>0,$ the last draw must be a failure 
and $r' = r - 1$ (leading to cases \textit{rC,rD} in Figure \ref{fig_rec_selection_dynamic_fail}).
If $r=0,$ the last draw must be a success and $n_o' = n_o-1$ (cases \textit{A} to \textit{D})

% Figure \ref{fig_rec_selection_dynamic_fail} shows a graphical representation of the recursion, and 
%A mathematical derivation is provided in the appendix. 
%The recursion can be broken down in a recursion over $r$, determined by rejected draws, 
%and a recursion over $n_o$, determined by successful draws.  
%The recursion over $r$ is shown at the bottom of
%Figure \ref{fig_rec_selection_dynamic_fail} (cases \textit{rC,rD}). If the last draw was rejected, the sampling 
%prior to the last draw must have ended with $r-1$ rejected draws. We
%must simply track whether the last rejected draw was from a previously drawn parental lineage (case
%\textit{rD}), in which case the number of parental lineages is unchanged, or of a new lineage (case
%\textit{rC}), in which case the sample with $r-1$ rejections must have had exactly one fewer distinct parent and 
%one fewer derived parental allele than the full sample.  
 
%Thus we can obtain $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ from
%$\mathbf{T}_{r-1}\Coalc{i_p-1}{n_p-1}{i_o}{n_o}$ and $\mathbf{T}_{r-1}\Coalc{i_p}{n_p}{i_o}{n_o},$
%and recursively back to terms of the form $\mathbf{T}_{0}\Coalc{i_p'}{n_p'}{i_o}{n_o}$, with $n_p'\leq n_p$
  
%To progress further and express $\mathbf{T}_{0}\Coalc{\cdot}{\cdot}{i_o}{n_o}$ in terms of
%$\mathbf{T}_{r}\Coalc{\cdot}{\cdot}{\cdot}{n_o-1}$, we condition on the last successful draw. This
%last successful draw can be (Figure \ref{fig_rec_selection_dynamic_fail}) previously unsampled
%derived (A), sampled derived (B), unsampled ancestral (C), or sampled ancestral (D).
  
A challenge with this recursion is that the number of rejected lineages $r$ leading to each successful 
draw can be infinite, in principle.
 However, the probability of having $r$ selective deaths for a single successful draw decreases
rapidly with $r$, as $s^r.$ We therefore modify the Wright-Fisher model such that at most $r_{max}$ failed
draws \emph{per offpsring} are allowed, after which the next draw is immune to selection. Given
$s<1$, we can easily pick $r_{max}$ to ensure excellent convergence. For example, with $s=0.01$, 
which corresponds to $Ns=100$ with $N=10,000$, the probability of having more than 
four selective deaths is less than $10^{-10}$, and the probability of having more than 8 selective deaths is 
less than $10^{-20}.$ We have used $r_{max}=4$ in numerical calculations presented below. 

The number of terms to compute in this recursion is finite. Using caching to avoid re-computing previously computed values,
we can systematically compute all the terms in Equation \ref{fig_rec_selection_dynamic_fail}.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{fig/recurrence-selection-dynamic-failures-annotated.pdf}

  \caption{Recursion construct for transition probability with selection, accounting for multiple
    kinds of coalescent events. The right hand panel represents summands on the left graphically.
    Filled and empty circles represent derived and ancestral alleles. Solid and broken lines are
    successful lineage draws and re-draws due to selection. Double lines represent potentially
    multiple draws. Square brackets represent events in a smaller sample size ($n_o-1$). Summands
    (\textit{A-D}) are successful draws where the last lineage is ancestral (\textit{A,B}) or
    derived (\textit{C,D}). Note that these terms depend on the probability that there were between
    $0$ to $r_{max}$ selective events in sample size $n_o-1$. Terms \textit{rC} and \textit{rD}
    represent the probability that last selection re-draw was due to a lineage from outside
    (\textit{rC}) or within (\textit{rD}) the sample. See table \ref{tab_symbols} for notation used.
  }

  \label{fig_rec_selection_dynamic_fail}
\end{figure}
 
The set of selection transition probability matrices $\mathbf{T}$ requires $O(r_{max}n_o^2 n_p^2)$
operations to construct: Since each term $\mathbf{T}_{r}$ (with $r>0$)  in the recursion requires a constant number of operations, 
the computational complexity depends on the number of terms we need to calculate. We will need to compute terms of the form 
 $\mathbf{T}_{r}\Coalc{i_p'}{n_p'}{i_o'}{n_o'}$, with $1 \leq n_o'<n_o$, $i_o' \leq n_o'$, $0\leq i_p' \leq n_p' \leq n_p$, and $0\leq n_p' \leq (r_{max}+1) n_o$, 
 and $0\leq r \leq r_{max},$ leading to the bound $O(r_{max}n_o^2 n_p^2).$  
 
 
 The terms  $\mathbf{T}_{0}$ have a bound of the same form (i.e., there are at most $O(n_o^2 n_p^2)$ terms, each requiring $r_{max}$ computations).  
Finally, the truncated matrix $\mathbf{Q}_{n_o} = \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o}$ can be constructed in $O(n_o^4)$.


This is moderately more complex than in the neutral case, where recursions (first derived in \cite{BhaskarEtAl2014}) can be computed in $O(n_o^3)$.

\subsection{Calculation of allele frequency spectra}
\label{subsec_afs}

Once the truncated matrix
$\mathbf{Q}_{n_o} = \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o}$
(eq. \ref{eq_truncated}) is constructed, it can be used to calculate the allele frequency spectrum. To
validate the method, we first use the equilibrium distribution where exact solutions are available
\citep{Krukov2016}. In the infinite sites model at equilibrium, we can compute the
equilibrium \textit{AFS} $\Phi$ in a finite sample as a solution to a linear system:

\begin{equation}
  \label{eq_sfs_calc}
  \Phi = \mathbf{Q}\Phi  + n \mu e_1
\end{equation}
where $\mu$ is the per-site (forward) mutation rate, and $e_1$ is the first column of the identity
matrix of size $n$. Figure \ref{fig_strong-selection} shows the comparison of the \textit{AFS}
calculated from Equation \ref{eq_sfs_calc}, the diffusion approximation
\cite[eq. 9.23]{Ewens2004}, and the calculation performed in \texttt{Moments}
\citep{JouganousEtAl2017}. All the vectors are normalized such that $\sum_{i_o} \textit{AFS} = 1$.

Figures \ref{fig_strong-selection}A-C show that there is a disagreement between the exact
Wright-Fisher and the diffusion solutions for singletons and doubletons. This effect increases as in
large sample sizes, as $n \ra N$, and has been reported by \citep{BhaskarEtAl2014}. There is a also
a divergence at high frequency of the derived allele. %The Wright-Fisher and the present model are
%both absorbing at fixation of the derived allele, while the diffusion models are not. 

Figures \ref{fig_strong-selection}D-F show a comparison at strong negative $Ns=50$, with a
sample size of $100$ and population sizes ranging from $N=100$ to  $N=1000.$  
The recursions presented here provide excellent agreement with the exact result even 
where the diffusion-based approaches fail. 

When the sample is the entire population, as in panels C and F, the present method is not needed since
exact recursion equations can be obtained from the binomial distribution 
(\textit{i.e.}, there is no computational benefit to consider a subsample that is as large as the entire population). 
The present approach will be useful if exact recursions can be obtained for sample sizes that are appreciably smaller
than $N$. We therefore seek asymptotic results for the convergence of the recursion approach.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textheight]{fig/strong_selection_six_panel.pdf}
  \caption{Normalized allele frequency spectra in a sample of size $n=100$, for neutral (Ns=0)
    (A,B,C), or highly deleterious alleles ($Ns=50$) (D,E,F). (A) shows the frequency spectrum in a
    sample from a large population ($N=1000$), (B) intermediate ($N=500$), and (C) small population
    ($N=100$). (D,E,F) same, for deleterious allele. The Y-axes are at different scales between the
    panels, to better indicate disagreement. The X-axes for panels (D,E,F) were truncated
    when the \textit{AFS} probability dropped below $10^{-12}$. }
  \label{fig_strong-selection}
\end{figure}

\subsection{Missing probability}
\label{subsec_missing}

Truncation in equation \ref{eq_truncated} means that if $n_p > n_o$, some probability will be lost. 

The $(i_p,i_o)^\text{th}$ element of matrix $\mathbf{Q}_{n_o}$ is the probability
$P_{n_o}(\mathcal{S'}_{n_o} (i_o)| \mathcal{C'}(i_p,n_p))$ of event $\ms'_{n_o}(i_o)$ that we observe $i_o$ derived alleles in
a sample of size $n_o$ and that we draw \emph{at most} $n_o$ distinct parental lineages (see \ref{subsec_apx_tpm_deriv}), 
given event $\mathcal{C'}(i_p,n_p)$ that $i_p$ of the first $n_p$ parental alleles are derived.

By summing $\sum_{i_o} \mathbf{Q}_{n_o}(i_p, i_o),$ we therefore get the proportion of draws that
were not truncated. $1-\sum_{i_o} \mathbf{Q}_{n_o}(i_p, i_o)$ is therefore the fraction of
unaccounted-for draws due to truncation, given $i_p$ derived among the first $n_o$ parental
alleles. Since only derived lineages experience selection, the largest number of resampling events,
and therefore the largest number of unaccounted lineages, occurs when all alleles are derived,
$i_p = n_o$.

Figure \ref{fig_apx_missing} shows the probability of missing lineages under this worst-case scenario. The 
probability first increases with increasing sample size, as the number of draws that can
result in selective deaths increases. However, the number of drift events eventually overtakes the
number of selective events, and the probability that we need additional lineages decreases rapidly
with sample sizes. With sufficiently large sample sizes, the missing probability can be made very small.

\subsection{Distribution of number of sampled lineages}
\label{subsec_distribution}

To get an analytical expression for the probability of missing lineages, in the worst-case scenario
where all the parental alleles are derived, we consider the probability that $n_p$ parents have been
sampled,

\begin{equation}
  \begin{aligned}
    \label{eq_conditional}
    P_{n_o}(n_p) = \sum_{n_g} P_{n_o}(n_p | n_g)P_{n_o}(n_g) 
  \end{aligned}
\end{equation}
where $n_p$ and $n_g$ is the number of sampled parents and gametes, respectively (Fig.
\ref{fig_schematic}C). 

The distribution over the number of gametes, $n_g$, is given by the negative binomial,
parameterized by the number of successes $n_o$, and the probability of a successful draw is $1-s$.

\begin{equation}
  \begin{aligned}
    \label{eq_neg_binomial_trials}
    P_{n_o}(n_g) = \binom{n_g-1}{n_o-1}(1-s)^{n_o}(s)^{n_g-n_o},
  \end{aligned}
\end{equation}
Given $n_g$, the number of parental lineages $n_p$ follows the modified occupancy distribution
(also known as the Arfwedson distribution) \citep{Wakeley2009,ONeill2019,JohnsonEtAl2005}: 

\begin{equation}
  \begin{aligned}
    \label{eq_occupancy}
    P(n_p|n_g) = \frac{S_2(n_g,n_p) N!}{(N-n_p)! N^{n_g}}
  \end{aligned}
\end{equation}
where $S_2(n_g,n_p)$ is a Stirling number of the second kind, which is the number of ways to
partition $n_g$ gametes into $n_p$ parents (see \cite{JohnsonEtAl2005} section 10.4 for a thorough
treatment).
Note that the occupancy distribution requires exchangeability of the alleles, which we satisfy by
assuming that all the alleles are derived, looking for the upper bound on the number of the
required lineages.

Combining the two distributions together through equation \ref{eq_conditional}, we get:

\begin{equation}
  \begin{aligned}
    \label{eq_lineages_in_past}
    P(n_p|n_o) = \sum_{n_g=1}^{\infty} \frac{S_2(n_g,n_p) N!}{(N-n_p)! N^{n_g}} \binom{n_g-1}{n_o-1}(1-s)^{n_o}(s)^{n_g-n_o}
  \end{aligned}
\end{equation}

We did not find an analytical expression for this sum, but it can be computed
efficiently using methods presented in \citep{ONeill2019}. Figure \ref{fig_combined}A (dotted line) shows
the distribution of the number of contributing parental lineages for several selection coefficients
with $n_o=200$.
As the strength of selection
is increased, we begin requiring larger numbers of lineages, while with increasing sample size,
there is a decrease in required lineages due to coalescent events.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{fig/combined.pdf}
  \caption{\textbf{A} The distribution of number of required lineages with $n_0=200$. Shaded
    red area shows missing probability, where $n_p > n_o$. Points represent the exact probability one
    generation into the past (Eq. \ref{eq_lineages_in_past}), solid lines - Gaussian approximation
    (Eq. \ref{eq_gaussian}). \textbf{B} Sample size ($n_o$) as a fraction of population size ($N$)
    such that we have $99\%$ confidence that no lineages are missing, derived from the Gaussian
    approximation. The dotted line indicates regimes where the Gaussian approximation is likely inaccurate. 
     In both panels, $N=1000$.}
  \label{fig_combined}
\end{figure}

\subsection{Gaussian approximation}
\label{subsec_gaussian}

The distribution in equation \ref{eq_lineages_in_past} can quickly be calculated numerically, but
provides little intuition. To get more intuition, we will first compute the
expectation and variance of this distribution, and then show that it can be accurately approximated by a
Gaussian distribution in useful parameter regimes.

Using the law of total expectation, we can write the expectation $E[n_p-n_o | n_o]$ as 
\begin{equation*}
  \begin{aligned}
    \label{eq_lineages_approx}
    E[n_p-n_o | n_o] &=        E[n_p | n_o]       - n_o \\
                     &=E_{n_g} E_{n_p}[n_p | n_g] - n_o.
  \end{aligned}
\end{equation*}

The expectation over $n_p$ is simply that of the occupancy distribution \cite{Wakeley2009}.

\begin{equation*}
  \begin{aligned}
    \label{eq_lineages_derive}
    \hat{E}[n_p -n_o | n_o]
    & =   E_{n_g}\left[N\left[1-\left(1 - \frac{1}{N} \right)^{n_g} \right]\right]- n_o\\
    & =   N-N  E_{n_g}\left[\left(1 - \frac{1}{N} \right)^{n_g} \right] -n_o. 
  \end{aligned}
\end{equation*}

As mentioned above, the number of selective deaths, $n_g-n_o$ follows a negative binomial
distribution with success probability $1-s$. We can use the moment generating function of the negative binomial to compute the
expectation of $k^{n_g}$ for any constant $k$:

%\begin{equation}
%E_{n_g}[k^{n_g}] = k^{n_o}  \left(\frac{1-s}{1-sk}\right)^{n_o}.
%\label{eq_identity}
%\end{equation} 
%\sgcomment{I believe that the general case is:}
\begin{equation}
  E_{n_g}[k^{n_g}] = k^{n_o}  \left(\frac{1-s}{1-sk}\right)^{n_o}.
  \label{eq_identity}
\end{equation} 


Thus we can write:

% \begin{equation}
%\begin{aligned}
% \label{eq_gauss_mean}
% \hat{E}[n_p -n_o | n_o] &= N-N\left( 1 - \frac{1}{N} \right)^{n_o}\left( \frac{1-s}{1-s \left( 1 - \frac{1}{N} \right)}\right)^{n_o}-n_o.
%\end{aligned}
% \end{equation}

%\sgcomment{General case}

\begin{equation}
  \begin{aligned}
    \label{eq_gauss_mean}
    \hat{E}[n_p -n_o | n_o] &= N-N\left( 1 - \frac{1}{N} \right)^{n_o}\left( \frac{1-s}{1-s \left( 1 - \frac{1}{N} \right)}\right)^{n_o}-n_o.
  \end{aligned}
\end{equation}

Taking the terms of order up to $\frac{1}{N}$ gives

\begin{equation}
    \label{eq_lineages_approx}
    \hat{E}[n_p-n_o | n_o] \approx n_o  s - \frac{n_o (n_o-1) }{2N}. 
\end{equation}

We thus have the usual interplay of selection and drift. Solving for $ \hat{E}[n_p -n_o | n_o]<0$
yields, to leading order,

\begin{equation}
  \label{eq_critical_sample}
  n_o^* \ge 2N s.
\end{equation}

This represents a critical sample size (Fig.
\ref{fig_apx_critical_normal}) where there is more drift than selection events, on average. 
The appendix outlines a similar approach to compute the variance of this distribution, $\operatorname{Var}[n_p-n_o | n_o].$ 
To leading order in $s,$ $n_o/N,$ and $1/N,$ the variance is 

\begin{equation}
  \begin{aligned}
    \operatorname{Var}[n_p-n_o | n_o] &\simeq
   n_o  s +   n_o (n_o-1)/(2 N).
    \label{eq_gauss_var}
  \end{aligned}
\end{equation}
% N(  \frac{n_o}{N} x s + n_o (n_o-1)^2/(2 N^2)) =

Thus the mean and variance to leading order are those of the Skellam distribution: the
\textit{increase} in lineages can be modelled, to lowest order, as the number of lineages gained
through selection (modelled as Poisson with mean  $ n_o s$) minus the number of lineages lost to
drift (modelled as an independent Poisson variable with mean  $ n_o (n_o-1)/(2 N)$).
As the number of drift and selection events get larger, the Skellam distribution can be approximated as a
Gaussian:

\begin{equation}
  P(n_p|n_o) \sim \mathcal{N}(\mu, \sigma).
  \label{eq_gaussian}
\end{equation}

Figure \ref{fig_combined}A shows the excellent agreement between the exact distribution and the
Gaussian approximation (using the exact variance from Equation \ref{eq_exact_var}). By contrast,
we don't expect this approximation to work well if the sample size is so small that few drift
events occur at a given generation, (say, $\frac{{n_o}^2}{2N} < 10$), where the Skellam
distribution is a better fit - Figure \ref{fig_apx_skellam}.
 
The Gaussian approximation using leading order terms provides intuition about regimes where we
expect drift to almost always overtake selection.  Concretely, if we solve for the sample size
$n_z$ required such that the ratio of the mean to the standard deviation is $z$, such that a value
of $z=3$ would entail that $99.9\%$ of lineages are accounted for under the Gaussian approximation,
we get, for $n_z\gg 1$,

\begin{equation}
  n_z \lessapprox 2 \sqrt{N} z + 2N s.
\label{eq_nz}
\end{equation}
with assumptions of the approximation are outlined in \ref{subsec_apx_gauss}. 

The second term
encodes the condition that there are more coalescence events than selection events, on average. The
first term is independent of $s$ and can be interpreted as a condition that there are sufficient
drift events per generation to ensure that the probability of having zero drift event is weak: $n_z
= 2 \sqrt N z$ implies $\frac{n_z^2}{2N}= 2 z$. One interpretation is that we need at least a few
expected coalescence events per generation to ensure that every selective event is compensated by a
coalescence event. 

Alternatively, we can solve for the quantiles of the Gaussian approximation (eq. \ref{eq_gaussian})
numerically. For a fixed $z=3$, Figure \ref{fig_combined}B shows how $n_c/N$ (sample as a fraction
of the population size) increases with stronger selection. Together with equation \ref{eq_nz}, this shows
that the truncation can be accurate even for strong selection and sample sizes much smaller than
the full population size. 

The action of selection can me modulated by the proprtion of the derived lineages $x_p$ in the
parental generation. Until now, we have regarded all the parental lineages as derived: $x_p=1$ (or
equivalently  $i_p = n_p$). We can add this approximate this effect in equation \eqref{eq_nz} by
modifying the selection term:

\begin{equation*}
  n_z \leq 2 \sqrt{N} z + 2Nsx_p
\end{equation*}

So in cases where ancestral alleles exist in the sample, the effect of selection will be
diminished further.

\subsection{Integrating over several generations} 

If $n_z$ is still too large for easy computation because of the $2 \sqrt{N} z$ term, we can improve 
the truncation by integrating over more than one generation.
Lineages gained by selective death at one generation can be compensated for by genetic drift at
another generation.

To get an idea of the truncation behavior for small number $g$ of generations, we can approximate 
the change  in the number of lineages as we go back in time as a random walk with constant mean and 
variance. In this case, both the mean and variance will be scaled by a factor $g$ relative 
to the single-generation case, and Equation \eqref{eq_nz} becomes:

\begin{equation}
  n_z \lessapprox 2 z\sqrt{N/g} + 2N s x_p.
\label{eq_nzg}
\end{equation}

If we have enough generations before this approximation breaks down, we can obtain nearly-closed
recursions if $n_o> 2Ns$. The computation of multi-generational matrices is described in
\ref{subsec_apx_multi}.

\section{Conclusion}
\label{sec_conclusion}

%Classically, the coalescent considers models in the absence of natural selection. Since selection
%can increase the number of contributing lineages back in time, the coalescent can no longer be
%represented by trees, but instead acquires a graph structure. The ancestral selection graphs
%\citep{KroneNeuhauser1997} deal with this in the limit of large population size ($N$).

Classical coalescent models in population genetics neglect the possibility that multiple coalescent events 
can co-occur within a single generation. 
Recent work \citep{BhaskarEtAl2014,NelsonEtAl2019} pointed out that this
assumption is problematic for sample sizes found in modern experiments. As a result, models
that consider multiple coalescent events per generation are gaining increased relevance in the field.
However, generalized coalescent models that can handle multi-way mergers are difficult to reconcile 
with selection models.

In this work, we show that increasing the sample size has an unexpected beneficial consequence. 
As sample size increases, the number of distinct parents relevant to a sample becomes, 
with high probability, smaller than the sample itself. Even though this does not rescue
all desirable properties of coalescent models, it means that recursion equations 
needed to calculate sample properties become nearly closed. 

The recursion equations themselves  are expressed in terms of combinatorial probabilities 
that can themselves be computed recursively in polynomial time. These computations 
remain costly, especially if transition matrices must be computed for time-dependent
population sizes and selection coefficients. It is likely that further computational 
speed ups, possibly involving approximations, can be derived for such cases.  

We have presented the current approach as an alternative to jackknife approximations in 
achieving moment closure. The two approaches are not mutually exclusive. 
Even though we have focused here on showing that approximate closure can be reached within 
a finite sample to high confidence, sampling instances that do not close can still be handled 
using jackknife approximations. Whereas the jackknife approach of \cite{JouganousEtAl2017} requires 
jackknifing a new lineage out of thin air every time a selection event occurs, the approach presented
here can be used to draw a new lineage only when no drift event has occurred. 
Thus it may not be necessary to reach closure at extremely high accuracy to achieve high accuracy
gains. 

Approximate closure of recursions requires the simulated sample size to be above a critical size of $2N_e s.$ 
It is not uncommon to perform simulations of allele frequencies to model datasets with hundreds or 
thousands of samples \citep{Gravel:2011bg, Tennessen:2012ck}. 
Such simulations would already be in the regime where even strong selection will be overcome by drift. For
example, $2N_e s = 100$ corresponds to a fixation probability reduced by a factor $4\times 10^{-42}$ relative 
to the neutral expectation \cite{Kimura:1962um}. 
 
The probability that selective events are reliably compensated by drift events is a more challenging requirement. 
Even if we chose to include drift over multiple generations, the present approach is relevant when 
$\sqrt{N}\lessapprox n \ll N$, that is, when the sample size is large enough that coalescences  are likely to
occur at each generation, but small enough that focusing on the finite sample provides a useful speedup 
relative to modelling the entire population. As argued in \citep{BhaskarEtAl2014},  this is a parameter regime
 relevant to present-day human samples.  

One of the main benefits of studying large sample sizes of whole-genome
genetic data is to refine our understanding of strongly deleterious variation \cite{karczewski2020mutational}. Performing 
quantitative inference for such datasets will require models that can handle both strong selection and large sample sizes.  
Since the transition matrices defined here can be used in both forward \citep{JouganousEtAl2017} 
and backward approaches \cite{KammEtAl2017}, the can help genetic models catch up with the requirements of genetic data.


\bibliography{disco}

\section{Appendix}
% \renewcommand{\thefigure}{S\arabic{figure}}
% \setcounter{figure}{0}

\subsection{Additional figures}
\label{subsec_apx_figures}

%\subsection{Missing lineages}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{fig/missing.pdf}
  \caption{Probability that there are more contributing parents than offspring: $n_p > n_o$.
    Calculated as $1-\sum_{i_o} \mathbf{Q}_{n_o}{i_p, i_o}$, with $N=1000$.}
  \label{fig_apx_missing}
\end{figure}

%\subsection{Quantiles of the Gaussian approximation}

%Figure \ref{fig_apx_critical_normal} shows the critical sample size for a given quantile of the normal
%approximation, as a function of the population-scaled selection coefficient. The $50^{\text{th}}$
%percentile corresponds to the mean calculated in equation \ref{eq_critical_sample} ($\approx 2Ns$).
%If we want to ascertain that the distribution is closed with increased confidence, we require a
%larger number of lineages. All curves assume $N=1000$.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{fig/critical_normal.pdf}
  \caption{Critical sample size that is required to ensure that a given proportion of simulated
  draws are included, for a given closure confidence level. The
    $50^\text{th}$ percentile corresponds to the mean in the equation \eqref{eq_critical_sample}. Note that the
    normal approximation is invalid for $Ns=0$, where the occupancy distribution should be used. All
    lines are calculated with $N_e=1000$.}
  \label{fig_apx_critical_normal}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{fig/skellam.pdf}
  \caption{Skellam approximation to the number of required lineages where $n_o$ is small:
  $\frac{{n_o}^2}{2N} < 10$. The Skellam distribution describes the difference between the number
  of offspring lineages $n_o$, and parental lineages $n_p$. }
  \label{fig_apx_skellam}
\end{figure}

\subsection{Variance of number of contributing lineages}
\label{subsec_apx_variance}

We can obtain the variance of the distribution of the number of parental lineages $P(n_p | n_o)$ by using the law of total variance:

\begin{equation}
  \label{eq_apx_var}
\Var\left[n_p-n_o \right] = \Var_{n_g}\left[E\left[n_p-n_o | n_g \right]\right]+  E_{n_g}\left[Var\left[n_p-n_o | n_g \right]\right] 
\end{equation}

As previously, we are assuming that all the parental alleles are derived.

The expectation in the first term can be derived from the occupancy distribution and the identity
\ref{eq_identity}:
\begin{equation}
\begin{split}
\Var_{n_g}\left[E\left[n_p-n_o | n_g \right]\right] &= \Var_{n_g}\left[E\left[n_p| n_g \right]\right] \\
&= \Var_{n_g}\left[N\left(1-(1-\frac{1}{N})^{n_g} \right) \right] \\ 
&= N^2 \Var_{n_g}\left[(1-\frac{1}{N})^{n_g} \right] \\
&= N^2 \left( E_{n_g}\left[(1-\frac{1}{N})^{2n_g} \right] - E_{n_g}\left[(1-\frac{1}{N})^{n_g} \right]^2\right) \\
&= N^2 \left( \left(1-\frac{1}{N}\right)^{2n_o} \left(\frac{1-s}{1-s  \left(1-\frac{1}{N}\right)^2}\right)^{n_o} 
-   \left(1-\frac{1}{N}\right)^{2n_o} \left(\frac{1-s}{1-s  \left(1-\frac{1}{N}\right)}\right)^{2n_o} \right) \\
\end{split}
\end{equation}

The variance of the second term of Equation \eqref{eq_apx_var} is the variance of the modified occupancy
distribution \cite{JohnsonEtAl2005}:

\begin{equation}
\begin{split}
E_{n_g}\left[Var\left[n_p-n_o | n_g \right]\right] & = E_{n_g}\left[N ((N - 1) (1 - 2/N)^{n_g} + (1 - 1/N)^{n_g} - N (1 - 1/N)^{2 n_g}) \right] \\
& = N (N-1)  \left(1-\frac{2}{N}\right)^{n_o} \left(\frac{1- s}{1- s  \left(1-\frac{2}{N}\right)}\right)^{n_o} +  \left(1-\frac{1}{N}\right)^{n_o} \left(\frac{1- s}{1- s  \left(1-\frac{1}{N}\right)}\right)^{n_o} \\
&-N  \left(1-\frac{1}{N}\right)^{2n_o} \left(\frac{1-  s}{1- s  \left(1-\frac{1}{N}\right)^2}\right)^{n_o}. 
\end{split}
\end{equation}

Combining the two terms in Equation \eqref{eq_apx_var}, we get

\newcommand{\vara}[1]{\left(1-\frac{#1}{N}\right)}
\newcommand{\varb}[1]{\left(\frac{1-s}{1-s #1}\right)}

\begin{equation}
  \begin{aligned}
    \operatorname{Var}[n_p-n_o | n_o] &=
    N^2\left( \vara{1}^{2n_o}\varb{\vara{1}^2}^{n_o}-\vara{1}^{2n_o}\varb{\vara{1}}^{2n_o} \right) + \\
    &+ N(N-1)\vara{2}^{n_o}\varb{\vara{2}} + \vara{1}^{n_o}\varb{\vara{1}}^{n_o} - \\
    &- N\vara{1}^{2n_o} \varb{\vara{1}^{2}}^{n_o}.
    \label{eq_exact_var}
  \end{aligned}
\end{equation}

Taking series expansion in Mathematica, we can show that  

\begin{equation}
  \begin{aligned}
    \operatorname{Var}[n_p-n_o | n_o] &= n s + \frac{n (n-1)}{2 N_e}  + \cdots
    \label{eq_exact_var}
  \end{aligned}
\end{equation}
where missing terms are of at least second order in products of  $s$, $\frac{n}{N}$,  and $\frac{1}{N}.$

\subsection{Simplifying Gaussian approximation}
\label{subsec_apx_gauss}

\begin{equation}
\begin{aligned}
  z &= \frac{X-\mu}{\sqrt{\sigma^2}} \\
  z &= \frac{-\left(  n_zs - \frac{n_z(n_z-1)}{2N} \right)}	{\sqrt{n_zs + \frac{n_z(n_z-1)}{2N}}} \\
  z &\approx \frac{\frac{n_z^2}{2N} - n_z s}	{\sqrt{n_zs + \frac{n_z^2}{2N}}} \\
  z &\geq \frac{\frac{n_z^2}{2N} - n_z s}{n_z / \sqrt{N}} \\
  \frac{z}{\sqrt{N}} &\geq \frac{n_z}{2N} - s \\
  2\sqrt{N}z &\geq n_z - 2Ns \\
  n_z &\leq 2\sqrt{N}z + 2Ns
\end{aligned}
\end{equation}

The approximation on line 3 is made assuming that there is more drift than selection, so that $n_zs
\leq \frac{n_z^2}{2N}$. Thus, the variance is smaller than twice the drift term: $\left(n_zs +
\frac{n_z^2}{2N} \right) \leq \left(\frac{n_z^2}{2N} + \frac{n_z^2}{2N} \right)$.

\subsection{Construction of transition probability matrices with multiple generations}
\label{subsec_apx_multi}

Such multi-generation transition matrices can also be computed by iterating equation \eqref{eq_recur}. 
Assuming, for simplicity, that the population sizes and selection coefficients are constant over the last two generations, 
and using matrix products to account for sums over the number $i_p$ of parental derived alleles, we find 
\begin{equation}
\begin{split}
\afs{n_o}{t} &=  \sum_{n_p=1}^{n_{p,max}}  \mathbf{T}_{n_p,n_o}     \afs{n_p}{t-1}\\
&=  \sum_{n_p=1}^{n_{p,max}} \mathbf{T}_{n_p,n_o}     \sum_{n'_p=1}^{n'_{p,max}}  \mathbf{T}_{n'_p,n_p}\afs{n'_p}{t-2}\\
&=  \sum_{n'_p=1}^{n'_{p,max}}  \left(\sum_{n_p=1}^{n_{p,max}} \mathbf{T}_{n_p,n_o}      \mathbf{T}_{n'_p,n_p} \right)\afs{n'_p}{t-2}\\
&\equiv  \sum_{n'_p=1}^{n'_{p,max}}  T^{(2)}_{n_p',n_o} \afs{n'_p}{t-2}.
\end{split}
\end{equation}
where $n'_{p'}$ is the number of sampled lineages in the grandparental generation, and $n_{p,max}$ and $n'_{p,max}$ are the maximum number of 
sampled parental alleles considered in the parental and grandparental generations, respectively.  We can choose $n_{p,max}>n_o$ and
$n_{p,max} = n_o$  to preserve closure of the moment equation while allowing for drift to cancel out selection events over the course of two generations. 

Since each matrix product takes $O(n_o n_p n_{p'})$, and there are at most $O(n_{p,max})$ such products, the computation of this
matrix product takes at most $O(n_o n_{p,max}^2 n_{p'}).$ This scaling can be improved upon in numerical 
implementations by summing only over values of $n_p$ that contribute appreciably. 
In addition, we need to build the matrices $T_{n_p', n_p}$ themsleves. 
In the recursive approach, the computation of the matrix for the largest sample includes the computation of matrices for
smaller sample sizes, so the computation time is at most that of the largest possible matrix, $O(r_{max} n_{p,max}^2, n_{p',max}^2).$ 
In the exact formulation of our model, $n_p$ can be as large as $ r_{max} n_o,$ however this would require every draw to be rejected by selection and
 only contribute terms of order $s^{n_o r_{max}}.$ A numerically appropriate cutoff for a given $n_o$ and $s$ can be computed dynamically 
 by keeping track of the proportion of unaccounted-for lineages. In most practical applications with $s<0.1$ we expect that choosing, e.g.,  
 $n_{p,max}=  2 n_o$ would provide excellent convergence, hence an overall scaling of   $O(r_{max} n_{o}^4)$ for the construction of 
 the matrices and $O(n_o^4)$ for the matrix product.
Thus a naive construction of a transition matrix over $g$ generations would require  $O( (g + r_{max} ) n_o^4).$ 

\subsection{Deriving the recursion on the transition matrices}
\label{subsec_apx_tpm_deriv}

The transition matrices $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ are defined in terms of sampling
probabilities $P(\ms_{n_o}(i_o, n_p, r) | \CC{(i_p,n_p)} ),$ where $\ms_{n_o}(i_o,n_p, r)$ is the
event that $i_o$ of the first $n_o$ offspring carry the derived allele, that the $r$
draws following the $n_o$th drawn offspring are rejected, and that at the end of the $r$th
rejection we have drawn exactly $n_p$ parents . Our goal here is to derive a recursion
over the last event $\ell$. We characterize the last draw event in terms of whether it is
successful ($\sigma_\ell=1$) or not ($\sigma_\ell=0$); whether it draws a derived allele
($\gamma_\ell=1$) or not ($\gamma_\ell=0$), and whether it draws a previously undrawn parental
allele ($\delta_\ell=1$) or not ($\delta_\ell=0$).

With this notation in place, we can write our recursion as: 
 \begin{equation}
  P( \ms_{n_o}(i_o, n_p, r) | \CC{(i_p,n_p)} ) = \sum_\ell P( \ms_{i_o, n_o}(n_p, r),\ell | \CC(i_p,n_p) ) . 
 \end{equation}

Now that we have explicitly specified the last draw $\ell,$ we can remove the corresponding
information from event $\ms,$ 

\begin{equation}
  P(\ms_{n_o}(i_o, n_p, r) | \CC{(i_p,n_p)} ) = \sum_\ell \sum_{r' \in R_\ell} P(\ms_{n'_o}(i_o',
  n'_p, r),\ell | \CC{(i_p,n_p)} ) . 
\end{equation}
where $i_o' = i_o-\gamma_\ell$,  $n_o' = n_o-\sigma_\ell,$ $i'_p= i_p - \delta_\ell \gamma_\ell,$  and $n'_p  = n_p - \delta_\ell$ represent the 
counts of derived and total alleles among the offspring and parents prior to the last draw. 
 The number of failures $r'$ can take more than one value if the last draw was a success,
so that 

\begin{equation}
  R_\ell = \begin{cases} 
    \{r-1\}    & \text{for } \sigma_\ell = 0, \\
    \mathbb{N} & \text{for } \sigma_\ell = 1.
  \end{cases}
\end{equation} 

We can further simplify the notation by defining shorthand for events prior to the last draw,
 $\ms' = \ms_{n'_o}(i_o', n'_p, r)$, and $\CC' = \CC{(i'_p,n'_p)}$, and after the
last draw $\ms = \ms_{n_o}(i_o, n_p, r)$, and $\CC = \CC{(i_p,n_p)}$

The event  $\CC'$ is fully determined by  $\CC$ and $\ell$, so that we can write

\begin{equation}
  \begin{split}
    \mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o} = P(\ms| \CC) &= \sum_\ell \sum_{r' \in R_\ell}
    P(\ms',\ell | \CC) \\ 
    &=\sum_\ell \sum_{r' \in R_\ell}P( \ms',\ell, \CC' |\CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P(\ell | \ms', \CC', \CC ) P( \ms'| \CC', \CC)  P(\CC' |\CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P(\ell | \ms', \CC', \CC ) P( \ms'| \CC')       P(\CC' |\CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P(\ell | \ms', \CC', \CC ) P(\CC' |\CC)  \mathbf{T}_{r}\Coalc{i'_p}{n'_p}{i'_o}{n'_o}
  \end{split}
\end{equation}
where the third line is an application of the chain rule and the fourth line uses the independence
of primed events on the last draw.  We now simply need to enumerate all the distinct types of
events for the last draw and compute the corresponding probabilities, which we do on Figure
\ref{fig_rec_selection_dynamic_fail}.

\end{document}
