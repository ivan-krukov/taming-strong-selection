\documentclass[review,nonatbib]{elsarticle}

\usepackage[]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{float}

% biblatex + elsarticle fix
\makeatletter
\let\c@author\relax
\makeatother

\usepackage[natbib=true,citestyle=authoryear]{biblatex}
\addbibresource{taming-strong-selection.bib}

\newcommand{\ra}{\rightarrow}
\newcommand{\afs}[2]{\Phi_{#1}^{(#2)}}
\newcommand{\Dfrac}[2]{%
  \ooalign{%
    $\genfrac{}{}{1.2pt}0{#1}{#2}$\cr%
    $\color{white}\genfrac{}{}{.4pt}0{\phantom{#1}}{\phantom{#2}}$}%
}
\newcommand{\cond}{\middle\vert}
\newcommand{\dslash}{/\!\!/}
\newcommand{\Coalc}[4]{\begin{bmatrix}#1\dslash #2 \\ #3\dslash #4 \end{bmatrix}}

\newcommand{\CC}{\mathcal{C}}
\newcommand{\ms}{\mathcal{S}}
\newcommand{\QQ}{\mathcal{Q}}

\newcommand{\sgcomment}[1]{{\color{red}{SG: #1}}}
\newcommand{\ikcomment}[1]{{\color{blue}{IK: #1}}}
\newcommand{\Var}{\operatorname{Var}}
\journal{Theoretical Population Biology}

\begin{document}
\begin{frontmatter}
  \title{ Taming strong selection with large sample sizes. }

  \author{Ivan Krukov}
  \author{Simon Gravel}

  \begin{abstract}

    The fate of mutations and the genetic load of populations depend on the relative importance of
    genetic drift and natural selection. In addition, the accuracy of numerical models of evolution
    depends on the strength of both selection and drift: strong selection breaks the assumptions of
    the nearly neutral model, and strong drift coupled with large sample sizes breaks
    Kingman's coalescent model.

    Thus, the regime with strong selection and large sample sizes, relevant to the study of pathogenic
    variation, appears particularly daunting.  Surprisingly, we find that strong drift in large
    samples compensates for the effects of selection. This competition between drift and selection
    can be used to define asymptotically closed recursions for the distribution of allele
    frequencies that are accurate well beyond the strong selection limit.

    Selection becomes more analytically tractable when the sample size $n$ is larger than twice the
    population-scaled selection coefficient: $n \ge 2Ns$ ($4Ns$ in diploids). In this regime, the
    expected number of coalescent events is larger than the number of selective events.  We
    construct the relevant transition matrices, show how they can be used to accurately compute
    distributions of allele frequencies, and discuss the boundaries of this analytically tractable
    regime.

  \end{abstract}

\end{frontmatter}

\section{Introduction}
\label{sec_introduciton}

The allele frequency spectrum (\textit{AFS}) is an important summary of genetic diversity that is
commonly used to infer demographic history and natural selection (\textit{e.g.}
\cite{GutenkunstEtAl2009, KammEtAl2017, JouganousEtAl2017}). Given a demographic scenario of
population size histories and migrations, these approaches use versions of the diffusion
approximation or coalescent simulations can to obtain a predicted \textit{AFS}. By comparing
predictions to the observed \textit{AFS}, one can compute likelihoods for different demographic
scenarios. These approaches share two drawbacks.

First, the \textit{AFS} calculations can be time consuming for large sample sizes.  Some efficient
computational shortcuts can be used (e.g., \citep{fastsimcoal2, KammEtAl2017}) but these often
require neutrality.  In the presence of natural selection, available methods are more limited, and
often involve forward simulations or variants of the diffusion
approximation \citep{GutenkunstEtAl2009, JouganousEtAl2017}.

Second, both Kingman's coalescent and diffusion-based models rely on an approximation that sample
sizes are smaller than the square root of the effective population size ($n < \sqrt{N}$), an increasingly
problematic assumption \citep{Fu2006, BhaskarEtAl2014}. The assumptions of Kingman's coalescent can
be relaxed to include more general models, involving multiple mergers (e.g., \cite{Fu2006,
Spence2016}, and references therein), but accounting for selection remains challenging.

Since a large body of work aimed at understanding the distribution of fitness effects for new
mutations relies on the diffusion approximation (\textit{e.g.} \cite{EyreWalker2006}), an approach
to handle large sample sizes and natural selection is important. In previous work
\cite{JouganousEtAl2017}, we suggested that a moments-based recursion approach to compute the AFS
could be modified to include multiple-merger events.

This approach presents two challenges.

First, the recursions are not closed under natural selection and require closure approximations that
become less reliable under strong selection.  Closure of the moment equations under the neutral
Wright-Fisher model occurs because the number $n_p$ of distinct parental lineages that are sampled
when drawing $n_o$ offspring lineages is at most $n_o$, and can be less if common ancestors are
found (\textit{i.e.}, if there are coalescent events): $n_p \le n_o$ (see Table \ref{tab_symbols}
for the notation used). This does not hold under negative selection -- selective deaths can require
the drawing of $n_p>n_o$  \citep{DonnellyKurtz1999a, JouganousEtAl2017}. This possible increase is
made explicit, for example, in the framework of the ancestral selection graph
\citep{KroneNeuhauser1997}.

Second, the additional combinatorial possibilities brought forth by multiple mergers  make the
computation of transition matrices for recursion equations more difficult.

In this article we derive the transition matrices for recursion equations, and show that the
additional effort in bookkeeping for large sample sizes has the unexpected benefit of solving our
selection challenge by making the recursions asymptotically closed.

The number of relevant lineages as we go back in time is a random variable that depends on the
relative importance of drift (controlled by the population size $N$) and selection (controlled by
the selection coefficient $s$), but also on the sample size $n_o$.  The number of in-sample
coalescent events per generation scales as the square of the sample size $n_o$, while the number of
selective deaths is linear in $n_o$. For sufficiently large samples, the expected number of
selective deaths will be smaller than common ancestry events, which would prevent the increase in
the number of lineages. If we can show that this holds not just in expectation, but almost always,
we can obtain recursion equations that are almost closed.

We show that these transition matrices can be used to accurately model the distribution of allele
frequencies in moderate to large samples and strong selection. The implementation of our methods,
and the source code for the figures are available at
\url{github.com/ivan-krukov/taming-strong-selection}.


\section{Background}
\label{sec_background}

We consider a haploid Wright-Fisher model with $N$ individuals per generation, focusing on a single
biallelic locus. For a present-day sample with $n_o$ offspring lineages at time $t$, we will be
looking for recursion equations for the allele frequency spectrum, $\afs{n_o}{t}(i_o)$, which we
define as the probability of observing $i_o$ copies of the derived allele in a sample of size $n_o$.
We will do so by considering the process of drawing parental alleles (at time $t-1$) for this finite
sample.

\begin{table}
  \centering
  \begin{tabular}{l|p{100mm}}
    Symbol & Meaning\\
    \hline
    $N$ & Population size\\
    $n_p$ & Number of sampled parental lineages (actual plus rejected samples due to selective deaths)\\
    $n_g$ & Number of gametes (intermediate)\\
    $n_o$ & Number of offspring, sample size\\
    $i_p$ & Number of derived alleles in parents\\
    $i_o$ & Number of derived alleles in offspring\\
    $t$ & Time, in generations\\
    $\Phi_{n_o}^{t}(i_o)$ & Allele frequency spectrum in $n_o$ at generation $t$\\
    $s$ & Selection advantage of the derived allele\\
    $r$ & Number of selection events (rejections) in the sample\\
    $x_p$ & Frequency of derived allele in parental generation\\
    $i_o \dslash n_o$ & A sample with $i_o$ derived alleles ``out of'' $n_o$ total lineages\\
    $\mathbf{H}\Coalc{i_p}{n_p}{i_o}{n_o}$ &
      Hypergeometric probability - sample $i_o \dslash n_o$ in offspring from
      $i_p \dslash n_p$ in parental generation\\
    $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ &
      Probability of transition from $i_p \dslash n_p$ in parents to $i_o \dslash n_o$ in offspring, 
      with $r$ selective events - see text for a more detailed description\\
    \hline
    $(i_p, n_p)$ & Event of \textit{drawing} exactly $i_p$ derived out of $n_p$ distinct parental lineages \\
    $\mathcal{C}(i_p, n_p)$ & Event of $n_p$ parental lineages \textit{containing} $i_p$ derived alleles \\
    $\mathcal{S}_{n_o}(i_o, n_p)$ & Event that $i_o$ out of $n_o$ offspring carry the derived allele and 
      that $n_p$ distinct parental alleles were drawn \\
    $\ms_{n_o}(i_o, n_p, r)$ & Event that  $i_o$ out of $n_o$ offspring carry the derived allele, 
      that the first $r$ draws for the
    $n_o+1$th offspring were rejected,
    and that $n_p$ distinct parental alleles were drawn (across all draws).
    %$\mathcal{Q}_{n_o}(i_o, r)$ & Event of $i_o$ of $n_o$ successfully drawn offspring lineages drawn with
     % $r$ selective deaths\\
  \end{tabular}
  \caption{\label{tab_symbols} Table of symbols}
\end{table}

To model selection as part of our sampling process, we consider that a parental lineage carrying a
derived allele can be `rejected' as a result of selective death with probability $s\ge0$ (Fig.
\ref{fig_schematic}B, broken lines). In such case, we keep sampling until a successful draw. This is
equivalent to the usual formulation of the Wright-Fisher model: the probability of drawing a copy of
the derived allele is $1-s$ times the probability of drawing a copy of the ancestral allele. And,
because the drawing process depends on the parental allele of both successful and rejected draws,
the \textit{AFS} in the offspring will depend on the state of the $n_p$ distinct parental lineages
that were sampled. Because of these selective rejections, $n_p$ can be larger than $n_o$.

To disentangle the effects of drift and selection, we may also make explicit the number of gametes
sampled in the process, $n_g$ (Fig. \ref{fig_schematic}C). The difference $n_g-n_o \ge 0$
depends on the number of selective deaths, whereas the difference $n_p-n_g \le 0$ depends
on the number of coalescent events. This distinction will be become particularly relevant in Section
\ref{subsec_distribution}.

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{fig/schematic.pdf}

  \caption{\label{fig_schematic} Realizations of sampling parental lineages under neutrality (A) and
    under selection (B,C). The top and bottom rows respectively represent the $n_p$ parents and
    $n_o$ offspring, with the middle row in panel (C) representing the $n_g$ gametes. Filled circles
    indicate the $i_p$, $i_g$, or $i_o$ copies of the derived allele; empty circles are ancestral
    alleles. A line connecting two circles represents a successful draw, a broken line - a selective
    death triggering a redraw. }

\end{figure}

To express the allele-frequency spectrum $\afs{n_o}{t}(i_o)$ for $n_o$ offspring in terms of the parental
\textit{AFS} at $t-1$, we can sum over random variables $n_p$ and the number $i_p$ of distinct derived alleles
among the parents:

\begin{equation}
  \afs{n_o}{t}(i_o)=P_{n_o} (i_o) =\sum_{n_p,i_p} P_{n_o}(i_o,i_p,n_p),
\end{equation}
where the subscript $n_o$ indicates dependence on parameter $n_o$. To obtain a recursion on the
\textit{AFS}, we use an exchangeability property of the parental lineages: the order in which we
draw previously unsampled parental lineages in the Wright-Fisher model is random.

In other words, we could first draw a random permutation of the parental population, and then select
unsampled parents in order from this permutation. We will separate properties of this permutation,
which depend only on parental \textit{AFS}, from properties of Wright-Fisher sampling, which depend
on population size and selection coefficients. Concretely, the event $(i_o,i_p,n_p)$ that we draw
$i_o$ derived offspring alleles from $n_p$ distinct parents of which $i_p$ are derived can be
expressed as the intersection of two events, $\mathcal{C}(i_p,n_p)$ and $\mathcal{S}_{n_o}(i_o,
n_p)$. Event $\mathcal{C}(i_p,n_p)$ specifies that the first $n_p$ parental lineages from the random
permutation carry $i_p$ derived alleles. Event $\mathcal{S}_{n_o}(i_o, n_p)$ requires that the
Wright-Fisher drawing process of $n_o$ offspring drew $i_o$ derived offspring alleles and sampled
exactly $n_p$ distinct parental lineages. Event $\mathcal{C}(i_p, n_p)$ depends on the allele
frequency distribution in the parental generation: $P(\mathcal{C}(i_p,n_p)) =\afs{n_p}{t} (i_p)$ by
definition of the \textit{AFS}. Thus

\begin{equation}
  \begin{split}
    \afs{n_o}{t}(i_o)&= \sum_{n_p,i_p} P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p), \mathcal{C}(i_p,n_p) )\\
    &=   \sum_{n_p,i_p} P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p)| \mathcal{C}(i_p,n_p) ) P(\mathcal{C}(i_p,n_p))\\
    &=   \sum_{n_p,i_p} P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p)| \mathcal{C}(i_p,n_p) )  \afs{n_p}{t-1}(i_p)%\\
%    \afs{n_o}{t} &\equiv  \sum_{n_p}  \mathbf{T}_{n_p,n_o}     \afs{n_p}{t-1}.
  \end{split}
\end{equation}
Using matrix notation to account for the sum over $i_p,$ we have
\begin{equation}
  \afs{n_o}{t} = \sum_{n_p}  \mathbf{T}_{n_p,n_o}     \afs{n_p}{t-1}
    \label{eq_recur}
  \end{equation}
where $\mathbf{T}_{n_p,n_o}(i_o,i_p) = P_{n_o}(\mathcal{S}_{n_o}(i_o, n_p)| \mathcal{C}(i_p,n_p) ) $ can be thought of as $(n_o+1) \times (n_p+1)$ transition
probability matrix, whose row and column indices correspond to the number of derived alleles in the
offspring and contributing parental lineages, respectively.

The AFS  $\afs{n_p}{t-1}$ for any  $n_p\leq n_o$ can be obtained by downsampling from $\afs{n_o}{t-1}$ (\textit{i.e.}, $\afs{n_p}{t-1} =
\mathbf{H}_{n_p,n_o} \afs{n_o}{t-1}$ for hypergeometric projection matrix $\mathbf{H}_{n_p,n_o}$ if
$n_p\leq n_o$). Thus, equation \eqref{eq_recur} provides a closed form recursion for $\Phi_{n_o}$ under neutrality.
This property was used in \cite{JouganousEtAl2017} to efficiently compute distributions of allele
frequencies under neutrality and in small sample sizes.

Under selection, $n_{p}$ may be larger than $n_o$, leading to a set of $N$ coupled equations that is
typically too large to solve numerically (in the diffusion limit, the number of coupled equations is
infinite). But if the number of drift events is typically larger than the number of selective
deaths, as happens in large sample sizes, the coupling is weak and we can restore approximate
closure by truncating the summation in Eq. \ref{eq_recur}:
\begin{equation}
\begin{split}
  \afs{n_o}{t}(i_o)
  &= \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o}  \afs{n_p}{t-1}+ \sum_{n_p> n_o }  \mathbf{T}_{n_p,n_o} \afs{n_p}{t-1} \\
  &=      \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o} \afs{n_o}{t-1}+ \sum_{n_p> n_o }  \mathbf{T}_{n_p,n_o} \afs{n_p}{t-1} \\
  &\approx\sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o} \afs{n_o}{t-1}+ \epsilon \\
  &\equiv \mathbf{Q}_{n_o}                                               \afs{n_o}{t-1}+ \epsilon
\end{split}
\label{eq_truncated}
\end{equation}
where $\mathbf{Q}_{n_o} =  \sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o}$ is a
square matrix whose $(i_p,i_o)^\text{th}$ element is the probability $P_{n_o}(\mathcal{S}_{\leq n_o}
(i_o)| \mathcal{C}(i_p,n_p))$ of event $\ms_{\leq n_o}(i_o)$ that we observe $i_o$ derived alleles
in a sample of size $n_o$ and that we draw \emph{at most} $n_o$ distinct parental lineages (see
Appendix \ref{subsec_apx_tpm_deriv}), given event $\mathcal{C}(i_p,n_p)$ that $i_p$ of the first
$n_p$ parental alleles are derived.  The term $\epsilon$ accounts for samplings with $n_p>n_o.$ A
jackknife approximation \citep{Gravel2016} can be used to simulate the drawing of additional
lineages ($\afs{n_p}{t} \simeq J_{n_p,n_o} \afs{n_o}{t}$ with $n_p>n_o$). \cite{JouganousEtAl2017}
used the jackknife to derive approximate recursion equations under weak selection. We will show
below that closure is asymptotically maintained for large sample sizes even without requiring a
jackknife approximation, i.e., by setting $\epsilon=0$. However, the jackknife can still be used in
practice to improve precision in some cases.

Our first goal is to obtain an explicit recursion for the matrices in \eqref{eq_recur}. To do so, we
will need to account for multiple coalescent events, which will require some careful bookkeeping.

\section{Methods and Results}
\label{sec_methods}

\subsection{Constructing the transition matrix}
\label{subsec_trans_mat}

Even though $\mathbf{T}_{n_p,n_o}$ in equation \ref{eq_recur} is a combinatorial probability
describing a single generation in the Wright-Fisher model, we were unable to compute an analytical
expression for it, while simultaneously allowing for multiple coalescences and multiple selective events.
However,
we can obtain fairly simple recursions by noting that properties of a sample of size $n_o$ are
related to properties of samples of size $n_o-1.$ Similar recursions on sample size were used for
describing large sample size effects without selection in \citep{BhaskarEtAl2014}. In this section,
we provide some mathematical intuition for the recursion equation, and a more detailed derivation is provided in
Appendix \ref{subsec_apx_tpm_deriv}.

We can think of Wright-Fisher sampling as being performed one offspring at a time, and even one draw
at a time. We will define recursions by conditioning on the last draw, whether it is accepted or
rejected.  The recursion will be over $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o},$ defined as the
probability $P_{n_o}\left[\ms_{n_o}(i_o, n_p, r) | \mathcal{C}(i_p, n_p)\right]$ where
$\ms_{n_o}(i_o, n_p, r),$ a generalization of  $\ms_{n_o}(i_o, n_p),$ is the event that $i_o$ of the
first $n_o$ successfully drawn offspring are derived, that the following $r$ draws are rejected, and
that the $n_o$ offspring and subsequent $r$ failures required exactly $n_p$ distinct parental draws.
This bracket notation is convenient to keep track of the number of relevant parental lineages (at
the top) and offspring lineages (at the bottom), similar to  figure \ref{fig_schematic}, at the cost
of obscuring their different probabilistic role.

The last draw can be characterized by whether it was successful or rejected, whether it drew a
derived or ancestral allele, and whether it drew a previously drawn parental lineage or not.
The state of the sampling process prior to the last draw can be described by a number of successfully drawn
offspring $n'_o$, of which $i'_o$ are derived, a number of distinct parental lineages
$n'_p$ of which $i'_p$ are derived, and a number of failures since last successful draw $r'$.
We show in the appendix and illustrate in Figure \ref{fig_rec_selection_dynamic_fail}  that we
can express $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ as a sum over a small number of terms
of the form $\mathbf{T}_{r'}\Coalc{i'_p}{n'_p}{i'_o}{n'_o}.$ If $r>0,$ the last draw must be a failure
and $r' = r - 1$ (leading to cases \textit{rC,rD} in Figure \ref{fig_rec_selection_dynamic_fail}).
If $r=0,$ the last draw must be a success and $n_o' = n_o-1$ (cases \textit{A} to \textit{D})

% Figure \ref{fig_rec_selection_dynamic_fail} shows a graphical representation of the recursion, and
%A mathematical derivation is provided in the appendix.
%The recursion can be broken down in a recursion over $r$, determined by rejected draws,
%and a recursion over $n_o$, determined by successful draws.
%The recursion over $r$ is shown at the bottom of
%Figure \ref{fig_rec_selection_dynamic_fail} (cases \textit{rC,rD}). If the last draw was rejected, the sampling
%prior to the last draw must have ended with $r-1$ rejected draws. We
%must simply track whether the last rejected draw was from a previously drawn parental lineage (case
%\textit{rD}), in which case the number of parental lineages is unchanged, or of a new lineage (case
%\textit{rC}), in which case the sample with $r-1$ rejections must have had exactly one fewer distinct parent and
%one fewer derived parental allele than the full sample.

%Thus we can obtain $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ from
%$\mathbf{T}_{r-1}\Coalc{i_p-1}{n_p-1}{i_o}{n_o}$ and $\mathbf{T}_{r-1}\Coalc{i_p}{n_p}{i_o}{n_o},$
%and recursively back to terms of the form $\mathbf{T}_{0}\Coalc{i_p'}{n_p'}{i_o}{n_o}$, with $n_p'\leq n_p$

%To progress further and express $\mathbf{T}_{0}\Coalc{\cdot}{\cdot}{i_o}{n_o}$ in terms of
%$\mathbf{T}_{r}\Coalc{\cdot}{\cdot}{\cdot}{n_o-1}$, we condition on the last successful draw. This
%last successful draw can be (Figure \ref{fig_rec_selection_dynamic_fail}) previously unsampled
%derived (A), sampled derived (B), unsampled ancestral (C), or sampled ancestral (D).

A challenge with this recursion is that the number of rejected lineages $r$ leading to each successful
draw can be infinite, in principle.
 However, the probability of having $r$ selective deaths for a single successful draw decreases
rapidly with $r$, as $s^r.$ We therefore modify the Wright-Fisher model such that at most $r_{max}$ failed
draws \emph{per offspring} are allowed, after which the next draw is immune to selection. Given
$s<1$, we can easily pick $r_{max}$ to ensure excellent convergence. For example, with $s=0.01$,
which corresponds to $Ns=100$ with $N=10,000$, the probability of having more than
three selective deaths is less than $10^{-6}$, and the probability of having more than 8 selective deaths is
less than $10^{-12}.$ We have used $r_{max}=3$ in numerical calculations presented below.

The number of terms to compute in this recursion is finite. Using caching to avoid re-computing
previously computed values, we can systematically compute all the terms in Equation
\ref{fig_rec_selection_dynamic_fail}.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{fig/recurrence-selection-dynamic-failures-annotated.pdf}

  \caption{Recursion construct for transition probability with selection, accounting for multiple
    kinds of coalescent events. The right hand panel represents summands on the left graphically.
    Filled and empty circles represent derived and ancestral alleles. Solid and broken lines are
    successful lineage draws and re-draws due to selection. Double lines represent potentially
    multiple draws. Square brackets represent events in a smaller sample size ($n_o-1$). Summands
    (\textit{A-D}) are successful draws where the last lineage is ancestral (\textit{A,B}) or
    derived (\textit{C,D}). Note that these terms depend on the probability that there were between
    $0$ to $r_{max}$ selective events in sample size $n_o-1$. Terms \textit{rC} and \textit{rD}
    represent the probability that last selection re-draw was due to a lineage from outside
    (\textit{rC}) or within (\textit{rD}) the sample. See table \ref{tab_symbols} for notation used.
  }

  \label{fig_rec_selection_dynamic_fail}
\end{figure}

The set of selection transition probability matrices $\mathbf{T}$ requires $O(r_{max}n_o^2 n_p^2)$
operations to construct: Since each term $\mathbf{T}_{r}$ (with $r>0$)  in the recursion requires a
constant number of operations, the computational complexity depends on the number of terms we need
to calculate. We will need to compute terms of the form
$\mathbf{T}_{r}\Coalc{i_p'}{n_p'}{i_o'}{n_o'}$, with $1 \leq n_o'<n_o$, $i_o' \leq n_o'$, and $0\leq
i_p' \leq n_p' \leq n_p$, and $0\leq r \leq r_{max},$ leading to the bound $O(r_{max}n_o^2 n_p^2).$

The terms  $\mathbf{T}_{0}$ have a bound of the same form (i.e., there are at most $O(n_o^2 n_p^2)$
terms, each requiring $r_{max}$ computations).  Finally, the truncated matrix $\mathbf{Q}_{n_o} =
\sum_{n_p=1}^{n_{o}} \mathbf{T}_{n_p,n_o} \mathbf{H}_{n_p,n_o}$ can be constructed in $O(n_o^4)$.

This is moderately more complex than in the neutral case, where recursions (first derived in
\cite{BhaskarEtAl2014}) can be computed in $O(n_o^3)$.

\subsection{Calculation of allele frequency spectra}
\label{subsec_afs}

Once the truncated matrix $\mathbf{Q}_{n_o}$ from Eq. \ref{eq_truncated} is constructed, it can be
used to calculate the allele frequency spectrum. To validate the method, we estimate the equilibrium
distribution where exact solutions are available \citep{Krukov2016}. In the infinite sites model at
equilibrium, we can compute the equilibrium \textit{AFS} $\Phi$ in a finite sample as a solution to
a linear system:

\begin{equation}
  \label{eq_sfs_calc}
  \Phi = \mathbf{Q}\Phi  + n \mu e_1
\end{equation}
where $\mu$ is the per-site (forward) mutation rate, $e_1$ is the second column of the identity
matrix of size $n+1.$ Since the infinite-sites model does not account for fixed sites,
we only report frequency spectra for polymorphic sites below.

Figure \ref{fig_strong_selection} shows the comparison of the \textit{AFS} calculated from Equation
\ref{eq_sfs_calc}, the diffusion approximation \cite[eq. 9.23]{Ewens2004}, and the numerical
calculation performed in \texttt{Moments} \citep{JouganousEtAl2017}. In all the panels, the sample
size is $n=200$ individuals. Any allele frequency probabilities below $1\times10^{-12}$ are not
included in the figures.

First, we note that our approach behaves in a way that is consistent with the Wright-Fisher
\textit{AFS} in all the examined parameter ranges. However, the diffusion-based approaches diverge
in several ways.

Figures \ref{fig_strong_selection}A,B show that there is a disagreement between the exact
Wright-Fisher and the diffusion solutions for singletons and doubletons. This effect increases with
sample size, and has been analyzed in \citep{BhaskarEtAl2014}. There is a also a strong divergence
at high frequency of the derived allele at neutrality, which has been noted in \citep{Fu2006}.

Figures \ref{fig_strong_selection}B,D show the special case where the sample is the entire
population, where the large sample effects are maximized. Note the difference in the $X$-axes for
these panels.

Figures \ref{fig_strong_selection}C,D show a comparison at moderate negative selection, $Ns=10$.
Here, we see a stronger difference between the models. An extended version of the figure can
be found in the appendix - \ref{fig_apx_strong_selection_extended}.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textheight]{fig/afs_comp_small.pdf}

  \caption{Relative error of allele frequency spectra in a sample of size $n=200$ with respect to
    the Wright-Fisher model. Neutral ($Ns$=0) (A,B), or deleterious alleles ($Ns=10$) (C,D). (A) shows
    the frequency spectrum in a sample from a large population ($N=2000$), (B) The sample is entire
    population ($n=N=200$). At neutrality all the models agree, except at high allele frequencies.
    With negative selection, the predictions differ substantially at moderate allele frequencies.
    Note that $Y$-axes are at different scales between the panels. An extended version of the figure
    is shown in the appendix - figure \ref{fig_apx_strong_selection_extended}.}

  \label{fig_strong_selection}
\end{figure}

The large disagreements between the models at high allele frequencies (Fig.
\ref{fig_strong_selection}) do not materialize, since the probabilities at those frequencies are
small. To show this, we demonstrate the difference in total genetic load in \textit{AFS} from our
method compared to the diffusion \textit{AFS}, which are shown in table \ref{tab_apx_load}. The total
load is small for both our model and the diffusion model, since most alleles are expected to exist
at small frequencies. While systematic differences exist, they are not substantial in practice.

Another possible consequence of the differences could be in the rates of fixation implied by the
different models. The diffusion approximation assigns higher probabilities to common deleterious
alleles, yielding a higher substitution rate. We show the results in figures
\ref{fig_apx_fixation_100} and \ref{fig_apx_fixation_1000}. In small populations, the difference is
somewhat large, but the effect disappears in larger populations \citep{Fu2006}. In both cases, the
largest differences only exists for strongly deleterious alleles, where the fixations are unlikely to begin
with. We note that these differences might be relevant on evolutionary time scales.

When the sample is the entire population, as in figures \ref{fig_strong_seelction} B and D, the
present method is not needed since exact recursion equations can be obtained from the binomial
distribution (\textit{i.e.}, there is no computational benefit to consider a subsample that is as
large as the entire population).  The present approach will be useful if exact recursions can be
obtained for sample sizes that are appreciably smaller than $N$. We therefore seek asymptotic
results for the convergence of the recursion approach in the following sections.

\subsection{Missing probability}
\label{subsec_missing}

%Truncation in equation \ref{eq_truncated} means that if $n_p > n_o$, some probability will be lost.

Given that $ \mathbf{Q}_{n_o}(i_p, i_o) = P_{n_o}(\mathcal{S}_{\leq n_o} (i_o)|
\mathcal{C}(i_p,n_p)),$ we can compute the fraction of unaccounted-for draws due to truncation,
given $i_p$ derived among the first $n_o$ parental alleles, as $1-\sum_{i_o} \mathbf{Q}_{n_o}(i_p,
i_o).$ Since only derived lineages experience selection, the largest number of resampling events,
and therefore the largest number of unaccounted lineages, occurs when all alleles are derived, $i_p
= n_o$.

Figure \ref{fig_apx_missing} shows the probability of missing lineages under this worst-case
scenario. The probability first increases with increasing sample size, as the number of draws that
can result in selective deaths increases. However, the number of drift events eventually overtakes
the number of selective events, and the probability that we need additional lineages decreases
rapidly with sample sizes. With sufficiently large sample sizes, the missing probability can be made
very small. In addition, we can use the jackknife approximation \citep{JouganousEtAl2017} to improve
model performance.

The transition probability matrices can be useful in numerical approaches, but they provide little
intuition about the general behaviour of the model. In the following sections, we derive
approximations to the process to gain more insight.

\subsection{Distribution of number of sampled lineages}
\label{subsec_distribution}

To get an analytical expression for the probability of missing lineages, in the worst-case scenario
where all the parental alleles are derived, we consider the probability that $n_p$ parents have been
sampled,

\begin{equation}
  \begin{aligned}
    \label{eq_conditional}
    P_{n_o}(n_p) = \sum_{n_g} P_{n_o}(n_p | n_g)P_{n_o}(n_g)
  \end{aligned}
\end{equation}
where $n_p$ and $n_g$ is the number of sampled parents and gametes, respectively (Fig.
\ref{fig_schematic}C).

The distribution over the number of gametes, $n_g$, is given by the negative binomial,
parameterized by the number of successes $n_o$, and the probability of a successful draw is $1-s$.

\begin{equation}
  \begin{aligned}
    \label{eq_neg_binomial_trials}
    P_{n_o}(n_g) = \binom{n_g-1}{n_o-1}(1-s)^{n_o}(s)^{n_g-n_o}.
  \end{aligned}
\end{equation}
Given $n_g$, the number of parental lineages $n_p$ follows the modified occupancy distribution
(also known as the Arfwedson distribution) \citep{Wakeley2009,ONeill2019,JohnsonEtAl2005}:

\begin{equation}
  \begin{aligned}
    \label{eq_occupancy}
    P(n_p|n_g) = \frac{S_2(n_g,n_p) N!}{(N-n_p)! N^{n_g}}
  \end{aligned}
\end{equation}
where $S_2(n_g,n_p)$ is a Stirling number of the second kind, which is the number of ways to
partition $n_g$ gametes into $n_p$ parents (see \cite{JohnsonEtAl2005} section 10.4 for a thorough
treatment).
The occupancy distribution requires exchangeability of the alleles, which is satisfied by the
condition that all parental alleles are derived.

Combining the two distributions together through equation \ref{eq_conditional}, we get:
\begin{equation}
  \begin{aligned}
    \label{eq_lineages_in_past}
    P(n_p|n_o) = \sum_{n_g=1}^{\infty} \frac{S_2(n_g,n_p) N!}{(N-n_p)! N^{n_g}} \binom{n_g-1}{n_o-1}(1-s)^{n_o}(s)^{n_g-n_o}
  \end{aligned}
\end{equation}

We did not find an analytical expression for this sum, but it can be computed
efficiently using methods presented in \citep{ONeill2019}. Figure \ref{fig_combined}A (dotted line) shows
the distribution of the number of contributing parental lineages for several selection coefficients
with $n_o=200$.
As the strength of selection
is increased, we begin requiring larger numbers of lineages, while with increasing sample size,
there is a decrease in required lineages due to coalescent events.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{fig/combined.pdf}
  \caption{\textbf{A} The distribution of number of required lineages with $n_0=200$. Shaded
    red area shows missing probability, where $n_p > n_o$. Points represent the exact probability one
    generation into the past (Eq. \ref{eq_lineages_in_past}), solid lines - Gaussian approximation.
     \textbf{B} Sample size ($n_o$) as a fraction of population size ($N$)
    such that we have $99\%$ confidence that no lineages are missing, derived from the Gaussian
    approximation. The dotted line indicates regimes where the Gaussian approximation is likely inaccurate.
     In both panels, $N=1000$.}
  \label{fig_combined}
\end{figure}

\subsection{Gaussian approximation}
\label{subsec_gaussian}

The distribution in equation \ref{eq_lineages_in_past} can quickly be calculated numerically, but
provides little intuition. We therefore compute the
expectation and variance of this distribution, and show that it can be accurately approximated by
Skellam and Gaussian distributions in useful parameter regimes.

Using the law of total expectation, we can write the expectation $E[n_p-n_o | n_o]$ as
\begin{equation*}
  \begin{aligned}
    \label{eq_lineages_approx}
    E[n_p-n_o | n_o] &=        E[n_p | n_o]       - n_o \\
                     &=E_{n_g} E_{n_p}[n_p | n_g] - n_o.
  \end{aligned}
\end{equation*}

The expectation over $n_p$ is simply that of the occupancy distribution \cite{Wakeley2009}.

\begin{equation*}
  \begin{aligned}
    \label{eq_lineages_derive}
    \hat{E}[n_p -n_o | n_o]
    & =   E_{n_g}\left[N\left[1-\left(1 - \frac{1}{N} \right)^{n_g} \right]\right]- n_o\\
    & =   N-N  E_{n_g}\left[\left(1 - \frac{1}{N} \right)^{n_g} \right] -n_o.
  \end{aligned}
\end{equation*}

As mentioned above, the number of selective deaths, $n_g-n_o$ follows a negative binomial
distribution with success probability $1-s$. We can use the moment generating function of the
negative binomial to compute the expectation of $k^{n_g}$ for any constant $k$:

%\begin{equation}
%E_{n_g}[k^{n_g}] = k^{n_o}  \left(\frac{1-s}{1-sk}\right)^{n_o}.
%\label{eq_identity}
%\end{equation}
%\sgcomment{I believe that the general case is:}
\begin{equation}
  E_{n_g}[k^{n_g}] = k^{n_o}  \left(\frac{1-s}{1-sk}\right)^{n_o}.
  \label{eq_identity}
\end{equation}

Thus we can write:

% \begin{equation}
%\begin{aligned}
% \label{eq_gauss_mean}
% \hat{E}[n_p -n_o | n_o] &= N-N\left( 1 - \frac{1}{N} \right)^{n_o}\left( \frac{1-s}{1-s \left( 1 - \frac{1}{N} \right)}\right)^{n_o}-n_o.
%\end{aligned}
% \end{equation}

%\sgcomment{General case}

\begin{equation}
  \begin{aligned}
    \label{eq_gauss_mean}
    \hat{E}[n_p -n_o | n_o] &= N-N\left( 1 - \frac{1}{N} \right)^{n_o}\left( \frac{1-s}{1-s \left( 1 - \frac{1}{N} \right)}\right)^{n_o}-n_o.
  \end{aligned}
\end{equation}

Taking the terms of order up to $\frac{1}{N}$ gives

\begin{equation}
    \label{eq_lineages_approx}
    \hat{E}[n_p-n_o | n_o] \approx n_o  s - \frac{n_o (n_o-1) }{2N}.
\end{equation}

We thus have the usual interplay of selection and drift. Solving for $ \hat{E}[n_p -n_o | n_o]\leq0$
yields, to leading order,

\begin{equation}
  \label{eq_critical_sample}
  n_o^* \ge 2N s.
\end{equation}

This represents a critical sample size (Fig.
\ref{fig_apx_critical_normal}) where there is more drift than selection events, on average.
The appendix outlines a similar approach to compute the variance of this distribution, $\operatorname{Var}[n_p-n_o | n_o].$
To leading order in $s,$ $n_o/N,$ and $1/N,$ the variance is

\begin{equation}
  \begin{aligned}
    \operatorname{Var}[n_p-n_o | n_o] &\simeq
   n_o  s +   n_o (n_o-1)/(2 N).
    \label{eq_gauss_var}
  \end{aligned}
\end{equation}
% N(  \frac{n_o}{N} x s + n_o (n_o-1)^2/(2 N^2)) =

Thus the mean and variance to leading order are those of the Skellam distribution: the
\textit{increase} in lineages can be modelled, to lowest order, as the number of lineages gained
through selection (modelled as Poisson with mean  $ n_o s$) minus the number of lineages lost to
drift (modelled as an independent Poisson variable with mean  $ n_o (n_o-1)/(2 N)$).
As the number of drift and selection events get larger, the Skellam distribution can be approximated as a
Gaussian with corresponding mean and variance.

%\begin{equation}
 % P(n_p|n_o) \sim \mathcal{N}(\mu, \sigma).
%  \label{eq_gaussian}
%\end{equation}

Figure \ref{fig_combined}A shows the excellent agreement between the exact distribution and the
Gaussian approximation (using the exact variance from Equation \ref{eq_exact_var}). By contrast,
we don't expect this approximation to work well if the sample size is so small that few drift
events occur at a given generation, (say, $\frac{{n_o}^2}{2N} < 10$), where the Skellam
distribution is a better fit - Figure \ref{fig_apx_skellam}.

The Gaussian approximation using leading order terms provides intuition about regimes where we
expect drift to almost always overtake selection.  Appendix \ref{subsec_apx_gauss} shows that the sample size
$n_z$ required such that the expected loss in the number of lineages is $z$ times its standard deviation,
such that a value of $z=3$ would entail that $99.9\%$ of lineages are accounted for under the Gaussian approximation,
obeys

\begin{equation}
  n_z \lessapprox 2 \sqrt{N} z + 2N s.
\label{eq_nz}
\end{equation}


The second term
encodes the condition that there are more coalescence events than selection events, on average. The
first term is independent of $s$ and can be interpreted as a condition that there are sufficient
drift events per generation to ensure that the probability of having zero drift event is weak: $n_z
= 2 \sqrt N z$ implies $\frac{n_z^2}{2N}= 2 z$. One interpretation is that we need at least a few
expected coalescence events per generation to ensure that every selective event is compensated by a
coalescence event at the same generation.

%Alternatively, we can solve for the quantiles of the Gaussian approximation (eq. \ref{eq_gaussian})
%numerically.
 For a fixed $z=3$, Figure \ref{fig_combined}B shows the critical sample size relative to the population size
 $(n_c/N)$. Together with equation \ref{eq_nz}, this shows
that the truncation can be accurate even for strong selection and sample sizes much smaller than
the full population size.

We can improve upon the bound from Equation \eqref{eq_nz} in two ways.
First, as we have argued above, the number of rejections is highest when $x_p=1$.
Under strong  negative selection, high derived allele frequencies are unlikely, and we may hope that the
criterion for practical convergence will occur earlier.
If we extrapolate the Poisson model of the drift vs selection interplay in equations \eqref{eq_lineages_approx} and \eqref{eq_gauss_var},
we can approximate the critical sample size for a given parental frequency as:
\begin{equation*}
  n_z \leq 2 \sqrt{N} z + 2Nsx_p.
\end{equation*}
Second, if $n_z$ is still too large for easy computation because of the $2 \sqrt{N} z$ term, we
can compute transition probabilities over a few generations to ensure that each selection event is met by a drift event.

\subsection{Integrating over several generations}

Computing accurate multi-generation transition matrices is reasonably straightforward
and not significantly more costly than computing single-generation matrices
(Appendix \ref{subsec_apx_multi}). To get an idea of the truncation behavior
for small number $g \ll N$ of generations, we can approximate the change  in the number
of lineages as we go back in time as a random walk with (approximately) constant mean and
variance. In this case, both the mean and variance will be scaled by a factor $g$ relative
to the single-generation case, and Equation \eqref{eq_nz} becomes:

\begin{equation}
  n_z \lessapprox 2 z\sqrt{N/g} + 2N s x_p.
\label{eq_nzg}
\end{equation}

For example, consider a population of size $N=10,000$ with strong selection
of $2Ns = 100,$ corresponding to a fixation probability reduced by a factor $4\times 10^{-42}$ relative
to the neutral expectation \cite{Kimura:1962um}.  If we set $z=5$ and $g=100,$ we require a sample size of at most $0.02 N.$
 If we choose to limit ourselves to smaller numbers of generations (say, $g=10$), the critical sample
 size is still much smaller than the entire population at $0.04N$.


\section{Conclusion}
\label{sec_conclusion}

%Classically, the coalescent considers models in the absence of natural selection. Since selection
%can increase the number of contributing lineages back in time, the coalescent can no longer be
%represented by trees, but instead acquires a graph structure. The ancestral selection graphs
%\citep{KroneNeuhauser1997} deal with this in the limit of large population size ($N$).

Classical coalescent models in population genetics neglect the possibility that multiple coalescent events
can co-occur within a single generation. \citep{BhaskarEtAl2014,NelsonEtAl2019} pointed out that this
assumption is problematic for sample sizes found in modern experiments \citep{Gravel:2011bg, Tennessen:2012ck}.
We have shown that problems of diffusion models become even more severe under negative selection.

Conveniently, we also showed that increasing the sample size has an unexpected beneficial consequence.
As sample size increases, the number of distinct parents relevant to a sample becomes,
with high probability, smaller than the sample itself. Even though this does not rescue
all desirable properties of coalescent models, it means that recursion equations
needed to calculate sample properties become nearly closed.

We have presented the current approach as an alternative to jackknife approximations in achieving
moment closure. The two approaches are not mutually exclusive. Even though we have focused here on
showing that approximate closure can be reached within a finite sample to high confidence by
truncation, sampling instances that do not close can still be approximatively closed using jackknife
approximations. Whereas the jackknife approach of \cite{JouganousEtAl2017} requires jackknifing a
new lineage every time a selection event occurs, the approach presented here can be used to draw a
new lineage only when drift fails to overcome selection (that is, only within small truncation term
$\epsilon$ in Equation \eqref{eq_truncated}).

The recursion equations themselves  are expressed in terms of combinatorial probabilities that can
be computed recursively in polynomial time. These computations remain costly if transition matrices
must be computed for time-dependent population sizes and selection coefficients. In such cases,
series expansion of transition matrices in terms of $s$, $\frac{n_o}{N}$ and $\frac{1}{N}$ may be
the most practical option.

%Here we have shown that setting the second term to zero can lead to asymptotically accurate computations.
%A jackknife approximation of the form $\afs{n_p}{t-1} \simeq J_{n_p, n_o} \afs{n_o}{t-1}$ for $n_p>n_o$ as in \cite{Gravel2016},
%would only require an approximation for the already small proportion of samplings that required $n_p>n_o.$


%Approximate closure of recursions requires the simulated sample size to be above a critical size of $2N_e s.$
%It is not uncommon to perform simulations of allele frequencies to model datasets with hundreds or
%thousands of samples \citep{Gravel:2011bg, Tennessen:2012ck}.
 %As argued in \citep{BhaskarEtAl2014},  this is a regime where diffusion-based approaches
 %struggle even under neutrality. We have shown that problems become even more severe under negative selection.

%  accurate simulations require accounting for multiple coalescence events.
% Conveniently, such simulations would also be in the regime where the present approaches would be accurate,
% meaning that selection can also be accounted for.


% relevant to present-day human samples.
%The probability that selective events are \emph{reliably} compensated by drift events, to the level of accuracy
%expected in most numerical approaches, is a more challenging requirement.
%Even if we chose to include drift over multiple generations, the present approach is relevant when
%$\sqrt{N}\lessapprox n \ll N$, that is, when the sample size is large enough that coalescences  are likely to
%occur at each generation, but small enough that focusing on the finite sample provides a useful speedup
%relative to modelling the entire population. As argued in \citep{BhaskarEtAl2014},  this is a parameter regime
% relevant to present-day human samples.

One of the main benefits of studying large sample sizes of whole-genome genetic data is to refine
our understanding of strongly deleterious variation \cite{karczewski2020mutational}. Performing
quantitative inference for such datasets will require models that can handle both strong selection
and large sample sizes.  Since the transition matrices defined here can be used in both forward
\citep{JouganousEtAl2017} and backward approaches \cite{KammEtAl2017}, they can help genetic models
catch up with the requirements of genetic data.

\printbibliography

\section{Appendix}

\newcommand{\beginsupplement}{%
        \setcounter{table}{0}
        \renewcommand{\thetable}{S\arabic{table}}%
        \setcounter{figure}{0}
        \renewcommand{\thefigure}{S\arabic{figure}}%
     }
\beginsupplement

\subsection{Additional figures}
\label{subsec_apx_figures}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{fig/afs_comp_big.pdf}

    \caption{Extended version of figure \ref{fig_strong_selection}. Relative error of allele
    frequency spectra from different models with respect to the Wright-Fisher \textit{AFS}. Panels
    horizontally - population size ($N=2000,1000,200$). Note that the last column corresponds to the
    special case where the sample is an entire population. Panels vertically - selection
    coefficients ($Ns=0,1,5,10,50$). Note that in the strong selection case ($Ns=50$), the $X$-axis
    is truncated, such that the total probability of an allele at any frequency is above $1e-12$.
    }

  \label{fig_apx_strong_selection_extended}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{fig/fixation_rate_N_100.pdf}

    \caption{(A) Fixation probability, (B) fixation load, and (C) relative error between the
    diffusion and Wright-Fisher models for N=100.}

  \label{fig_apx_fixation_100}

\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{fig/fixation_rate_N_1000.pdf}

    \caption{(A) Fixation probability, (B) fixation load, and (C) relative error between the
    diffusion and Wright-Fisher models for N=1000.}

  \label{fig_apx_fixation_1000}

\end{figure}
%\subsection{Missing lineages}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{fig/missing.pdf}

  \caption{Probability that there are more contributing parents than offspring: $n_p > n_o$.
    Calculated as $1-\sum_{i_o} \mathbf{Q}_{n_o}{(i_p, i_o)}$, with $N=1000$. Note that this does
    not use the Jackknife approximation.}

  \label{fig_apx_missing}
\end{figure}

%\subsection{Quantiles of the Gaussian approximation}

%Figure \ref{fig_apx_critical_normal} shows the critical sample size for a given quantile of the normal
%approximation, as a function of the population-scaled selection coefficient. The $50^{\text{th}}$
%percentile corresponds to the mean calculated in equation \ref{eq_critical_sample} ($\approx 2Ns$).
%If we want to ascertain that the distribution is closed with increased confidence, we require a
%larger number of lineages. All curves assume $N=1000$.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{fig/critical_normal.pdf}
  \caption{Critical sample size that is required to ensure that a given proportion of simulated
  draws are included, for a given closure confidence level. The
    $50^\text{th}$ percentile corresponds to the mean in the equation \eqref{eq_critical_sample}. Note that the
    normal approximation is invalid for $Ns=0$, where the occupancy distribution should be used. All
    lines are calculated with $N_e=1000$.}
  \label{fig_apx_critical_normal}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{fig/skellam.pdf}
  \caption{Skellam approximation to the number of required lineages where $n_o$ is small:
  $\frac{{n_o}^2}{2N} < 10$. The Skellam distribution describes the difference between the number
  of offspring lineages $n_o$, and parental lineages $n_p$. }
  \label{fig_apx_skellam}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{ c c r r r }
        N & Ns & $L$ & $L_{diffusion}$ & Relative error \\
        \hline
        $200$  & $0$  & $       0$ & $       0$ & $0\%$ \\
               & $1$  & $1.149e-8$ & $1.150e-8$ & $0.086\%$ \\
               & $5$  & $1.128e-8$ & $1.130e-8$ & $0.181\%$ \\
               & $10$ & $1.054e-8$ & $1.056e-8$ & $0.148\%$ \\
               & $20$ & $1.025e-8$ & $1.026e-8$ & $0.140\%$ \\
               & $50$ & $1.009e-8$ & $1.010e-8$ & $0.146\%$ \\
        \\
        $400$  & $0$  & $       0$ & $       0$ & $0\%$ \\
               & $1$  & $1.150e-8$ & $1.150e-8$ & $0.041\%$ \\
               & $5$  & $1.129e-8$ & $1.130e-8$ & $0.090\%$ \\
               & $10$ & $1.055e-8$ & $1.056e-8$ & $0.073\%$ \\
               & $20$ & $1.026e-8$ & $1.026e-8$ & $0.068\%$ \\
               & $50$ & $1.010e-8$ & $1.010e-8$ & $0.068\%$ \\
        \\
        $1000$ & $0$  & $       0$ & $       0$ & $0\%$ \\
               & $1$  & $1.150e-8$ & $1.150e-8$ & $0.016\%$ \\
               & $5$  & $1.130e-8$ & $1.130e-8$ & $0.036\%$ \\
               & $10$ & $1.056e-8$ & $1.056e-8$ & $0.028\%$ \\
               & $20$ & $1.026e-8$ & $1.026e-8$ & $0.027\%$ \\
               & $50$ & $1.010e-8$ & $1.010e-8$ & $0.026\%$ \\
        \\
        $2000$ & $0$  & $       0$ & $       0$ & $0\%$ \\
               & $1$  & $1.150e-8$ & $1.150e-8$ & $0.009\%$ \\
               & $5$  & $1.130e-8$ & $1.130e-8$ & $0.017\%$ \\
               & $10$ & $1.056e-8$ & $1.056e-8$ & $0.014\%$ \\
               & $20$ & $1.026e-8$ & $1.026e-8$ & $0.014\%$ \\
               & $50$ & $1.010e-8$ & $1.010e-8$ & $0.013\%$ \\
        \end{tabular}

    \caption{\label{tab_apx_load} Genetic load under the allele frequency
    spectra from present study ($L$), and the diffusion approximation
    ($L_{diffusion}$), with sample size $n=200$ individuals. Load calculated as
    $L=\sum_i s \frac{i}{n} \phi(i)$, relative error is
    $\frac{L-L_{diffusion}}{L}\times100\%$. }

\end{table}

\subsection{Deriving the recursion on the transition matrices}
\label{subsec_apx_tpm_deriv}

The transition matrices $\mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o}$ are defined in terms of sampling
probabilities $P(\ms_{n_o}(i_o, n_p, r) | \CC{(i_p,n_p)} ),$ where $\ms_{n_o}(i_o,n_p, r)$ is the
event that $i_o$ of the first $n_o$ offspring carry the derived allele, that the $r$
draws following the $n_o$th drawn offspring are rejected, and that at the end of the $r$th
rejection we have drawn exactly $n_p$ parents . Our goal here is to derive a recursion
over the last event $\ell$. We characterize the last draw event in terms of whether it is
successful ($\sigma_\ell=1$) or not ($\sigma_\ell=0$); whether it draws a derived allele
($\gamma_\ell=1$) or not ($\gamma_\ell=0$), and whether it draws a previously undrawn parental
allele ($\delta_\ell=1$) or not ($\delta_\ell=0$).

With this notation in place, we can write our recursion as:
 \begin{equation}
  P( \ms_{n_o}(i_o, n_p, r) | \CC{(i_p,n_p)} ) = \sum_\ell P( \ms_{n_o}(i_o, n_p, r),\ell | \CC(i_p,n_p) ) .
 \end{equation}

Now that we have explicitly specified the last draw $\ell,$ we can remove the corresponding
information from event $\ms,$

\begin{equation}
  P(\ms_{n_o}(i_o, n_p, r) | \CC{(i_p,n_p)} ) = \sum_\ell \sum_{r' \in R_\ell} P(\ms_{n'_o}(i_o',
  n'_p, r),\ell | \CC{(i_p,n_p)} ) .
\end{equation}
where $i_o' = i_o-\gamma_\ell$,  $n_o' = n_o-\sigma_\ell,$ $i'_p= i_p - \delta_\ell \gamma_\ell,$  and $n'_p  = n_p - \delta_\ell$ represent the
counts of derived and total alleles among the offspring and parents prior to the last draw.
 The number of failures $r'$ can take more than one value if the last draw was a success,
so that

\begin{equation}
  R_\ell = \begin{cases}
    \{r-1\}    & \text{for } \sigma_\ell = 0, \\
    \mathbb{N} & \text{for } \sigma_\ell = 1.
  \end{cases}
\end{equation}

We can further simplify the notation by defining shorthand for events prior to the last draw,
 $\ms' = \ms_{n'_o}(i_o', n'_p, r)$, and $\CC' = \CC{(i'_p,n'_p)}$, and after the
last draw $\ms = \ms_{n_o}(i_o, n_p, r)$, and $\CC = \CC{(i_p,n_p)}$

The event  $\CC'$ is fully determined by  $\CC$ and $\ell$, so that we can write

\begin{equation}
  \begin{split}
    \mathbf{T}_{r}\Coalc{i_p}{n_p}{i_o}{n_o} = P(\ms| \CC) &= \sum_\ell \sum_{r' \in R_\ell}
    P(\ms',\ell | \CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P( \ms',\ell, \CC' |\CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P(\ell | \ms', \CC', \CC ) P( \ms'| \CC', \CC)  P(\CC' |\CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P(\ell | \ms', \CC', \CC ) P( \ms'| \CC')       P(\CC' |\CC) \\
    &=\sum_\ell \sum_{r' \in R_\ell}P(\ell | \ms', \CC', \CC ) P(\CC' |\CC)  \mathbf{T}_{r}\Coalc{i'_p}{n'_p}{i'_o}{n'_o}
  \end{split}
\end{equation}
where the third line is an application of the chain rule and the fourth line uses the independence
of primed events on the last draw.  We now simply need to enumerate all the distinct types of
events for the last draw and compute the corresponding probabilities, which we do on Figure
\ref{fig_rec_selection_dynamic_fail}.


\subsection{Variance of number of contributing lineages}
\label{subsec_apx_variance}

We can obtain the variance of the distribution of the number of parental lineages $P(n_p | n_o)$ by using the law of total variance:

\begin{equation}
  \label{eq_apx_var}
\Var\left[n_p-n_o \right] = \Var_{n_g}\left[E\left[n_p-n_o | n_g \right]\right]+  E_{n_g}\left[Var\left[n_p-n_o | n_g \right]\right]
\end{equation}
As previously, we are assuming that all the parental alleles are derived.
The expectation in the first term can be derived from the occupancy distribution and the identity
\ref{eq_identity}:
\begin{equation}
\begin{split}
\Var_{n_g}\left[E\left[n_p-n_o | n_g \right]\right] &= \Var_{n_g}\left[E\left[n_p| n_g \right]\right] \\
&= \Var_{n_g}\left[N\left(1-(1-\frac{1}{N})^{n_g} \right) \right] \\
&= N^2 \Var_{n_g}\left[(1-\frac{1}{N})^{n_g} \right] \\
&= N^2 \left( E_{n_g}\left[(1-\frac{1}{N})^{2n_g} \right] - E_{n_g}\left[(1-\frac{1}{N})^{n_g} \right]^2\right) \\
&= N^2 \left( \left(1-\frac{1}{N}\right)^{2n_o} \left(\frac{1-s}{1-s  \left(1-\frac{1}{N}\right)^2}\right)^{n_o}
-   \left(1-\frac{1}{N}\right)^{2n_o} \left(\frac{1-s}{1-s  \left(1-\frac{1}{N}\right)}\right)^{2n_o} \right) \\
\end{split}
\end{equation}
The variance of the second term of Equation \eqref{eq_apx_var} is the variance of the modified occupancy
distribution \cite{JohnsonEtAl2005}:
% I think there was a mistake in here: changed this to be consistent with the code and mathematica
% notebook
\begin{equation}
\begin{split}
E_{n_g}\left[Var\left[n_p-n_o | n_g \right]\right] & = E_{n_g}\left[N ((N - 1) (1 - 2/N)^{n_g} + (1 - 1/N)^{n_g} - N (1 - 1/N)^{2 n_g}) \right] \\
% & = N (N-1)  \left(1-\frac{2}{N}\right)^{n_o} \left(\frac{1- s}{1- s  \left(1-\frac{2}{N}\right)}\right)^{n_o} +  \left(1-\frac{1}{N}\right)^{n_o} \left(\frac{1- s}{1- s  \left(1-\frac{1}{N}\right)}\right)^{n_o} \\
% &-N  \left(1-\frac{1}{N}\right)^{2n_o} \left(\frac{1-  s}{1- s  \left(1-\frac{1}{N}\right)^2}\right)^{n_o}.
&= N (N-1) \left( \frac{ (1-s)\left( 1-\frac{2}{N} \right) }{ 1-s\left( 1-\frac{2}{N} \right) } \right)^{n_o} + \\
&+ N \left( \frac{(1-s)\left( 1-\frac{1}{N} \right)}{1-s\left( 1-\frac{1}{N} \right)}\right)^{n_o} - \\
&- N^2 \left( \frac{(1-s)\left( 1-\frac{1}{N} \right)^2}{1-s\left( 1-\frac{1}{N} \right)^2}\right)^{n_o} \\
\end{split}
\end{equation}

Combining the two terms in Equation \eqref{eq_apx_var}, we get

\newcommand{\vara}[1]{\left(1-\frac{#1}{N}\right)}
\newcommand{\varb}[1]{\left(\frac{1-s}{1-s #1}\right)}

\begin{equation}
  \begin{aligned}
    \operatorname{Var}[n_p-n_o | n_o] &=
    N^2\left( \vara{1}^{2n_o}\varb{\vara{1}^2}^{n_o}-\vara{1}^{2n_o}\varb{\vara{1}}^{2n_o} \right) + \\
    &+ N (N-1) \left( \frac{ (1-s)\left( 1-\frac{2}{N} \right) }{ 1-s\left( 1-\frac{2}{N} \right) } \right)^{n_o} + N \left( \frac{(1-s)\left( 1-\frac{1}{N} \right)}{1-s\left( 1-\frac{1}{N} \right)}\right)^{n_o} - N^2 \left( \frac{(1-s)\left( 1-\frac{1}{N} \right)^2}{1-s\left( 1-\frac{1}{N} \right)^2}\right)^{n_o}.
    \label{eq_exact_var}
  \end{aligned}
\end{equation}

Taking series expansion in Mathematica \citep{Mathematica}, we can show that

\begin{equation}
  \begin{aligned}
    \operatorname{Var}[n_p-n_o | n_o] &= n s + \frac{n (n-1)}{2 N_e}  + \cdots
    \label{eq_exact_var}
  \end{aligned}
\end{equation}
where missing terms are of at least second order in products of  $s$, $\frac{n}{N}$,  and
$\frac{1}{N}.$ The code is available in the github repository.

\subsection{Simplifying Gaussian approximation}
\label{subsec_apx_gauss}
Given a $z$ for the change in the number of lineages of $ z = \frac{-\mu}{\sqrt{\sigma^2}},$
we use $\mu=\left(  n_zs - \frac{n_z(n_z-1)}{2N} \right)$ and $\sigma = \sqrt{n_zs +
\frac{n_z(n_z-1)}{2N}}$ from Equations \ref{eq_lineages_approx} and \ref{eq_gauss_var} to obtain a bound for $n_z$:


\begin{equation}
\begin{aligned}
  z &= \frac{-\left(  n_zs - \frac{n_z(n_z-1)}{2N} \right)}	{\sqrt{n_zs + \frac{n_z(n_z-1)}{2N}}} \\
  z &\approx \frac{\frac{n_z^2}{2N} - n_z s}	{\sqrt{n_zs + \frac{n_z^2}{2N}}} \geq \frac{\frac{n_z^2}{2N} - n_z s}{n_z / \sqrt{N}} \\
 \end{aligned}
\end{equation}
 The latter inequality uses the fact that we are in the regime where the expected number of drift events is larger than the number of
 selection events. Thus $\left(n_zs +
\frac{n_z^2}{2N} \right) \leq \left(\frac{n_z^2}{2N} + \frac{n_z^2}{2N} \right)$.

 This can now be trivially solved for $n_z$ to yield
 \begin{equation}
  n_z \leq 2\sqrt{N}z + 2Ns
\end{equation}

\subsection{Construction of transition probability matrices with multiple generations}
\label{subsec_apx_multi}

Multi-generation transition matrices can simply be computed by iterating equation \eqref{eq_recur}.
Assuming, for simplicity, that the population sizes and selection coefficients are constant over the
last two generations, and using matrix products to account for sums over the number $i_p$ of
parental derived alleles, we find
\begin{equation}
\begin{split}
\afs{n_o}{t} &=  \sum_{n_p=1}^{n_{p,max}}  \mathbf{T}_{n_p,n_o}     \afs{n_p}{t-1}\\
&=  \sum_{n_p=1}^{n_{p,max}} \mathbf{T}_{n_p,n_o}     \sum_{n'_p=1}^{n'_{p,max}}  \mathbf{T}_{n'_p,n_p}\afs{n'_p}{t-2}\\
&=  \sum_{n'_p=1}^{n'_{p,max}}  \left(\sum_{n_p=1}^{n_{p,max}} \mathbf{T}_{n_p,n_o}      \mathbf{T}_{n'_p,n_p} \right)\afs{n'_p}{t-2}\\
&\equiv  \sum_{n'_p=1}^{n'_{p,max}}  T^{(2)}_{n_p',n_o} \afs{n'_p}{t-2}.
\end{split}
\end{equation}
where $n'_{p'}$ is the number of sampled lineages in the grandparental generation, and $n_{p,max}$
and $n'_{p,max}$ are the maximum number of sampled parental alleles considered in the parental and
grandparental generations, respectively.  We can choose $n_{p,max}>n_o$ and $n_{p,max} = n_o$  to
preserve closure of the moment equation while allowing for drift to cancel out selection events over
the course of two generations.

Since each matrix product takes $O(n_o n_p n_{p'})$, and there are at most $O(n_{p,max})$ such
products, the computation of this matrix product takes at most $O(n_o n_{p,max}^2 n_{p'}).$ This
scaling can be improved upon in numerical implementations by summing only over values of $n_p$ that
contribute appreciably.  In addition, we need to build the matrices $T_{n_p', n_p}$ themselves.  In
the recursive approach, the computation of the matrix for the largest sample includes the
computation of matrices for smaller sample sizes, so the computation time is at most that of the
largest possible matrix, $O(r_{max} n_{p,max}^2, n_{p',max}^2).$ In the exact formulation of our
model, $n_p$ can be as large as $ r_{max} n_o,$ however this would require every draw to be rejected
by selection and only contribute terms of order $s^{n_o r_{max}}.$ A numerically appropriate cutoff
for a given $n_o$ and $s$ can be computed dynamically by keeping track of the proportion of
unaccounted-for lineages. In most practical applications with $s<0.1$ we expect that choosing, e.g.,
$n_{p,max}=  2 n_o$ would provide excellent convergence, hence an overall scaling of   $O(r_{max}
n_{o}^4)$ for the construction of the matrices and $O(n_o^4)$ for the matrix product.  Thus a naive
construction of a transition matrix over $g$ generations would require  $O( (g + r_{max} ) n_o^4).$



\end{document}
